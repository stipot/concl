{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# сравнение функций потерь от сжатого и сырого контекстов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "* Отладка. Проблема Сжатый контекст: N/A\n",
    "* Пересмотреть функцию потерь, чтобы она отражала задачу сжатия более точно (например, использовать потери восстановления или схожести между оригиналом и сжатым контекстом).\n",
    "* Усложнить архитектуру модели ContextOptimizer, добавив больше слоев или более продвинутые блоки, такие как GRU или LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Основная цель\n",
    "Обучить отдельную сеть \\( O \\) (модуль оптимизации контекста), которая динамически изменяет контекст таким образом, чтобы предсказания исходной языковой модели \\( M \\) оставались точными, несмотря на уменьшение объема информации в контексте.\n",
    "\n",
    "### Структура и Процесс Обучения\n",
    "\n",
    "1. **Основная Языковая Модель \\( M \\):**\n",
    "   - \\( M \\) — существующая языковая модель, такая как GPT-2, которая принимает на вход полный контекст и текущий фрагмент и генерирует предсказания.\n",
    "   - Цель \\( M \\) — максимальная точность предсказаний на основе полного контекста.\n",
    "\n",
    "2. **Модуль Оптимизации Контекста \\( O \\):**\n",
    "   - Модуль \\( O \\) используется для сжатия предыстории \\( C \\) с учетом текущего фрагмента \\( S \\), чтобы создать оптимизированный контекст \\( C' \\).\n",
    "   - Модуль \\( O \\) может быть реализован через нейронные сети, такие как трансформеры, рекуррентные сети или другие архитектуры, способные выделять ключевые элементы контекста.\n",
    "\n",
    "3. **Целевая Функция и Метрики:**\n",
    "   - Основной задачей является минимизация расхождения между предсказаниями модели \\( M \\) на основе \\( C' \\) и \\( C \\). Целевая функция может быть определена как:\n",
    "     \\[\n",
    "     L = \\text{Loss}(M(C', S), M(C, S))\n",
    "     \\]\n",
    "   - Для измерения качества сжатия можно использовать метрики, такие как среднеквадратичная ошибка (MSE) между эмбеддингами предсказаний, кросс-энтропия, и т.д.\n",
    "   - Важно также отслеживать сходимость потерь между \\( C' \\) и \\( C \\), чтобы убедиться, что \\( C' \\) минимально влияет на точность предсказаний.\n",
    "\n",
    "4. **Процесс Обучения:**\n",
    "   - **Шаг 1:** Из датасета создаются пары \\( (C, S, T) \\), где \\( C \\) — предыстория, \\( S \\) — текущий фрагмент, и \\( T \\) — целевой текст для предсказания.\n",
    "   - **Шаг 2:** Модуль \\( O \\) сжимает контекст \\( C \\), производя \\( C' = O(C, S) \\).\n",
    "   - **Шаг 3:** Модель \\( M \\) предсказывает на основе \\( (C', S) \\) и \\( (C, S) \\). Сравниваются предсказания для оценки потерь.\n",
    "   - **Шаг 4:** Потери используются для обновления параметров модуля \\( O \\), минимизируя влияние сжатия на точность.\n",
    "\n",
    "5. **Анализ и Диагностика:**\n",
    "   - Постепенно выводим промежуточные результаты для диагностики, включая анализ предсказаний по сжатому и полному контексту.\n",
    "   - Выполняем оценку примеров, где предсказания на основе сжатого контекста значительно отличаются от предсказаний на основе полного контекста.\n",
    "   - Используем фильтрацию данных для обучения, например, исключаем случаи, где текущий фрагмент уже достаточен для точного предсказания.\n",
    "\n",
    "### Рекомендации для Улучшения\n",
    "\n",
    "- **Итеративная Диагностика:** Важно регулярно проверять, насколько сжатый контекст \\( C' \\) сохраняет критическую информацию. Диагностика на нескольких примерах может выявить случаи, где \\( O \\) недооценивает важные части контекста.\n",
    "- **Контроль за Переобучением:** Следите за тем, чтобы модель \\( O \\) не начинала генерировать «фантазии» или добавлять избыточные детали в попытках компенсировать потерю информации.\n",
    "- **Улучшение Сходимости:** Добавьте регуляризацию или дополнительные ограничения на модель \\( O \\), чтобы предотвратить отклонения в сжатии, которые могут ухудшить точность предсказаний.\n",
    "\n",
    "### Ожидаемый Результат\n",
    "\n",
    "- Модуль \\( O \\) научится выделять только те части контекста, которые критически важны для точных предсказаний, избегая ненужного увеличения объема информации.\n",
    "- Модель \\( M \\), используя \\( C' \\), будет предсказывать с минимальной потерей точности, что укажет на успешное сжатие и оптимизацию контекста. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **Подготовка Данных**\n",
    "   - **Предварительная обработка данных:** Датасет разбивается на последовательности: предыстория (context), текущий фрагмент (current_fragment), и целевой текст (target).\n",
    "   - **Фильтрация данных:** Удаляются пустые и нерелевантные записи, например, те, где текущий фрагмент не вносит значимого вклада в предсказание.\n",
    "   - **Предварительная оценка потерь:** Вычисляются потери для различных комбинаций контекста, что позволяет заранее оценить вклад контекста в точность предсказания.\n",
    "\n",
    "### 2. **Оптимизация Контекста**\n",
    "   - **Целевая функция:** Используется MSELoss для измерения расхождения между предсказаниями модели и целевыми значениями.\n",
    "   - **Сходимость потерь:** Основная цель — сходимость потерь сжатого контекста (compressed_loss) к потерям сырого контекста (raw_loss).\n",
    "   - **Контроль за «додумыванием»:** Введены штрафы за значительное отклонение между потерями сжатого и сырого контекста, чтобы предотвратить генерацию ложных зависимостей.\n",
    "\n",
    "### 3. **Адаптивная Регуляция Потерь**\n",
    "   - **Штрафы за расхождения:** Если потери сжатого контекста значительно отличаются от потерь сырого, в потери добавляется штраф, который стимулирует модель уменьшать эти различия.\n",
    "   - **Адаптивное обучение:** Обучение адаптируется на основе расхождений, улучшая способность модели сжимать контекст, сохраняя при этом точность.\n",
    "\n",
    "### 4. **Использование Промежуточных Датасетов**\n",
    "   - **Сохранение промежуточных результатов:** Включение предсказаний модели в промежуточный датасет, чтобы ускорить и упростить анализ, отладку и последующую оптимизацию.\n",
    "   - **Фильтрация на этапе подготовки:** Отбираются записи, в которых контекст оказывает значительное влияние на предсказания, отбрасывая те, где контекст несущественен.\n",
    "\n",
    "### 5. **Визуализация и Отладка**\n",
    "   - **Графики потерь:** Построение графиков с использованием Plotly для отслеживания динамики потерь сжатого и сырого контекстов.\n",
    "   - **Примеры для анализа:** Регулярный вывод примеров с различными типами предсказаний (сжатый контекст, сырой контекст, текущий фрагмент) для визуального анализа и проверки корректности работы модели.\n",
    "\n",
    "### 6. **Управление Временем и Эффективностью**\n",
    "   - **Оценка времени:** Оценка времени выполнения подготовки данных и каждой эпохи обучения на основе первых пяти циклов, что позволяет планировать ресурсозатраты.\n",
    "   - **Оптимизация кода:** Фокусировка на ключевых этапах, таких как загрузка моделей, настройка параметров и запуск оптимизации с минимальными затратами времени.\n",
    "\n",
    "### Основные цели:\n",
    "- Обеспечение качественного сжатия контекста без потери точности.\n",
    "- Сведение к минимуму расхождения потерь между сжатым и сырым контекстами.\n",
    "- Избежание нежелательных интерпретаций и «додумывания» контекста моделью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модульная структура"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вспомогательные классы и методы\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch.nn as nn\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "# Подготовка данных\n",
    "def prepare_data(dataset, max_length=300):\n",
    "    \"\"\"\n",
    "    Функция подготавливает данные из датасета, включая предысторию, текущий фрагмент и целевой фрагмент текста,\n",
    "    используя смещающееся окно по элементам датасета.\n",
    "\n",
    "    :param dataset: Датасет с текстами.\n",
    "    :param max_length: Максимальная длина текущего фрагмента.\n",
    "    :return: Список кортежей (предыстория, текущий фрагмент, целевой фрагмент).\n",
    "    \"\"\"\n",
    "    prepared_data = []\n",
    "    buffer = []\n",
    "    counter = 0\n",
    "    for example in dataset:\n",
    "        text = example[\"text\"].strip()\n",
    "\n",
    "        # Пропускаем пустые записи\n",
    "        # TODO Убрать отладочную выборку первых 1000 записей\n",
    "        if len(text) == 0 or counter > 1000:\n",
    "            continue\n",
    "        counter += 1\n",
    "        buffer.append(text)\n",
    "\n",
    "        # Если буфер содержит три фрагмента, создаем (context, current_fragment, target)\n",
    "        if len(buffer) == 3:\n",
    "            context, current_fragment, target = buffer\n",
    "\n",
    "            # Обрезаем фрагменты по max_length, если необходимо\n",
    "            context = context[:max_length].strip()\n",
    "            current_fragment = current_fragment[:max_length].strip()\n",
    "            target = target[:max_length].strip()\n",
    "\n",
    "            # Пропускаем записи, если какой-либо из фрагментов пустой\n",
    "            if all([context, current_fragment, target]):\n",
    "                prepared_data.append((context, current_fragment, target))\n",
    "\n",
    "            # Сдвигаем окно\n",
    "            buffer.pop(0)\n",
    "    return prepared_data\n",
    "\n",
    "\n",
    "# Функции для сохранения и загрузки модели\n",
    "def save_model(model, optimizer, path=\"context_optimizer.pth\"):\n",
    "    torch.save(\n",
    "        {\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        },\n",
    "        path,\n",
    "    )\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "\n",
    "def load_model(model, optimizer, path=\"context_optimizer.pth\"):\n",
    "    if os.path.exists(path):\n",
    "        checkpoint = torch.load(path)\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        print(f\"Model loaded from {path}\")\n",
    "    else:\n",
    "        print(f\"Model file not found at {path}\")\n",
    "\n",
    "\n",
    "# Визуализация с использованием Plotly FigureWidget\n",
    "def create_loss_plot():\n",
    "    fig = go.FigureWidget()\n",
    "    fig.add_trace(go.Scatter(x=[], y=[], mode=\"lines+markers\", name=\"Raw Context Loss\"))\n",
    "    fig.add_trace(go.Scatter(x=[], y=[], mode=\"lines+markers\", name=\"Compressed Context Loss\"))\n",
    "    fig.add_trace(go.Scatter(x=[], y=[], mode=\"lines+markers\", name=\"Fragment Only Loss\"))\n",
    "    fig.update_layout(title=\"Графики потерь во время обучения\", xaxis_title=\"Эпоха\", yaxis_title=\"Среднее значение потерь\", template=\"plotly_dark\")\n",
    "    display(fig)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def update_loss_plot(fig, epoch, raw_loss, compressed_loss, fragment_loss):\n",
    "    fig.data[0].x += (epoch,)\n",
    "    fig.data[0].y += (raw_loss,)\n",
    "    fig.data[1].x += (epoch,)\n",
    "    fig.data[1].y += (compressed_loss,)\n",
    "    fig.data[2].x += (epoch,)\n",
    "    fig.data[2].y += (fragment_loss,)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# Функция для расчета compression ratio\n",
    "def calculate_compression_ratio(raw_embedding, compressed_embedding):\n",
    "    \"\"\"\n",
    "    Вычисляет отношение нормы сжатого контекста к норме сырого контекста.\n",
    "    \"\"\"\n",
    "    raw_norm = torch.norm(raw_embedding, p=2, dim=1)\n",
    "    compressed_norm = torch.norm(compressed_embedding, p=2, dim=1)\n",
    "    return compressed_norm / raw_norm\n",
    "\n",
    "\n",
    "def predict_with_compressed_context(current_fragment, tokenizer, gpt2_model, device, max_new_tokens=50, num_beams=5):\n",
    "    # Ensure the tokenizer is correctly initialized\n",
    "    if isinstance(tokenizer, GPT2Tokenizer):\n",
    "        # Set the pad_token to eos_token if not already set\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token  # Use eos_token as pad_token\n",
    "\n",
    "        # Tokenize the current fragment\n",
    "        inputs = tokenizer(current_fragment, return_tensors=\"pt\", padding=True).to(device)\n",
    "        input_ids = inputs.get(\"input_ids\")\n",
    "        attention_mask = inputs.get(\"attention_mask\")  # Adding attention_mask\n",
    "\n",
    "        # Check that input_ids is not empty\n",
    "        if input_ids is not None and input_ids.shape[1] > 0:\n",
    "            with torch.no_grad():\n",
    "                # Generate predictions directly from current_fragment\n",
    "                outputs = gpt2_model.generate(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,  # Use the attention mask\n",
    "                    max_new_tokens=max_new_tokens,\n",
    "                    num_beams=num_beams,\n",
    "                    early_stopping=True,\n",
    "                    pad_token_id=tokenizer.pad_token_id,  # Ensure pad_token_id is set correctly\n",
    "                )\n",
    "                predicted_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "                return predicted_text\n",
    "        else:\n",
    "            print(f\"Invalid inputs: input_ids length {input_ids.shape[1] if input_ids is not None else 'None'}\")\n",
    "    else:\n",
    "        print(\"Invalid tokenizer object. Ensure the tokenizer is an instance of GPT2Tokenizer.\")\n",
    "\n",
    "    return \"N/A\"\n",
    "\n",
    "\n",
    "# Использование предсказаний из предподготовленных данных\n",
    "def evaluate_with_prepared_data(prepared_data, model, tokenizer, gpt2_model, device):\n",
    "    \"\"\"\n",
    "    Выполняет оценку качества предсказаний с использованием подготовленных данных.\n",
    "    \"\"\"\n",
    "    for entry in prepared_data:\n",
    "        context = entry[\"context\"]\n",
    "        current_fragment = entry[\"current_fragment\"]\n",
    "        target = entry[\"target\"]\n",
    "        raw_prediction = entry[\"raw_prediction\"]\n",
    "        fragment_prediction = entry[\"fragment_prediction\"]\n",
    "\n",
    "        # Сжатие контекста и предсказание с ним\n",
    "        compressed_context = model.compress(context)  # Предположим, у нас есть метод compress в модели\n",
    "        compressed_prediction = predict_with_compressed_context(current_fragment, tokenizer, gpt2_model, device)\n",
    "\n",
    "        # Сравнение предсказаний\n",
    "        print(f\"Контекст: {context}\")\n",
    "        print(f\"Текущий фрагмент: {current_fragment}\")\n",
    "        print(f\"Целевой текст: {target}\")\n",
    "        print(f\"Предсказание по сырому контексту: {raw_prediction}\")\n",
    "        print(f\"Предсказание по текущему фрагменту: {fragment_prediction}\")\n",
    "        print(f\"Предсказание по сжатому контексту: {compressed_prediction}\\n\")\n",
    "\n",
    "\n",
    "def load_intermediate_dataset(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель сжатия контекста\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "\n",
    "class ContextOptimizer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=4, nhead=4):\n",
    "        super(ContextOptimizer, self).__init__()\n",
    "        self.encoder = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=input_size, nhead=nhead, dim_feedforward=hidden_size), num_layers=num_layers)\n",
    "        self.compress_fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, context):\n",
    "        # Предполагается, что context имеет форму (seq_len, batch_size, input_size)\n",
    "        encoded_context = self.encoder(context)\n",
    "        compressed_context = self.compress_fc(encoded_context.mean(dim=0))  # Среднее по всем токенам\n",
    "        return compressed_context\n",
    "\n",
    "\n",
    "# Функция для сжатия контекста\n",
    "def compress_context(context, optimizer, tokenizer, gpt2_model, device):\n",
    "    inputs = tokenizer(context, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = gpt2_model(**inputs, output_hidden_states=True)\n",
    "        raw_context_embedding = outputs.hidden_states[-1]  # Сохранение всех скрытых состояний\n",
    "\n",
    "    # Подготовка предыстории для подачи в модуль сжатия\n",
    "    context_embedding = raw_context_embedding.permute(1, 0, 2)  # Транспонируем для правильной формы\n",
    "    compressed_context = optimizer(context_embedding)  # Получаем сжатый контекст\n",
    "\n",
    "    return compressed_context, raw_context_embedding.mean(dim=1)  # Среднее значение как репрезентация предыстории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "\n",
    "def custom_loss(compressed_output, target_embedding, raw_context_embedding):\n",
    "    \"\"\"\n",
    "    Функция потерь, которая учитывает схожесть с оригиналом и целевым вектором.\n",
    "    \"\"\"\n",
    "    # Потеря восстановления: сравниваем сжатый контекст с исходным контекстом\n",
    "    reconstruction_loss = 1 - cosine_similarity(compressed_output, raw_context_embedding, dim=1).mean()\n",
    "\n",
    "    # Потеря предсказания: сравниваем предсказанный выход с целевым\n",
    "    prediction_loss = nn.MSELoss()(compressed_output, target_embedding)\n",
    "\n",
    "    # Итоговая потеря: комбинация восстановления и предсказания\n",
    "    total_loss = prediction_loss + reconstruction_loss\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def combined_loss(compressed_output, target_embedding, full_context_output, regularization_factor=0.01):\n",
    "    # Потеря предсказания\n",
    "    prediction_loss = nn.MSELoss()(compressed_output, target_embedding)\n",
    "\n",
    "    # Потеря восстановления для сохранения важной информации\n",
    "    reconstruction_loss = 1 - cosine_similarity(compressed_output, full_context_output, dim=1).mean()\n",
    "\n",
    "    # Регуляризация для предотвращения избыточности\n",
    "    regularization_loss = regularization_factor * torch.norm(compressed_output, p=1)\n",
    "\n",
    "    # Итоговая потеря\n",
    "    total_loss = prediction_loss + reconstruction_loss + regularization_loss\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def train_context_optimizer(optimizer, intermediate_data, tokenizer, gpt2_model, epochs=4, device=\"cpu\"):\n",
    "    opt = optim.Adam(optimizer.parameters(), lr=0.001)\n",
    "    raw_loss_values = []\n",
    "    compressed_loss_values = []\n",
    "    fragment_loss_values = []\n",
    "\n",
    "    # Инициализация графика потерь\n",
    "    loss_fig = create_loss_plot()\n",
    "    # Для отслеживания потерь по каждому примеру на каждой эпохе\n",
    "    example_loss_history = {i: [] for i in range(len(intermediate_data))}\n",
    "    for epoch in range(epochs):\n",
    "        total_compression_ratio = 0\n",
    "        total_compressed_loss = 0\n",
    "        total_divergence = 0  # Переменная для отслеживания расхождения между потерями\n",
    "        count = 0\n",
    "\n",
    "        epoch_losses = []  # Для хранения потерь текущей эпохи\n",
    "        examples_calculated = []\n",
    "        for idx, entry in enumerate(intermediate_data):\n",
    "            context = entry[\"context\"]\n",
    "            current_fragment = entry[\"current_fragment\"]\n",
    "            target = entry[\"target\"]\n",
    "\n",
    "            # Используем предвычисленные значения потерь для сырого контекста и текущего фрагмента\n",
    "            raw_loss = entry[\"raw_loss\"]\n",
    "            fragment_loss = entry[\"fragment_loss\"]\n",
    "\n",
    "            # Подготовка целевого предсказания\n",
    "            target_input = tokenizer(target, return_tensors=\"pt\").to(device)\n",
    "            with torch.no_grad():\n",
    "                target_output = gpt2_model(**target_input, output_hidden_states=True)\n",
    "                target_embedding = target_output.hidden_states[-1].mean(dim=1)\n",
    "\n",
    "            ## Сжатие контекста и вычисление потерь для сжатого контекста в комбинации с текущим фрагментом\n",
    "            compressed_context, raw_context_embedding = compress_context(context, optimizer, tokenizer, gpt2_model, device)\n",
    "            compressed_inputs = tokenizer(current_fragment, return_tensors=\"pt\").to(device)\n",
    "            compressed_context_repeated = compressed_context.unsqueeze(1).repeat(1, compressed_inputs[\"input_ids\"].size(1), 1)\n",
    "\n",
    "            # Преобразование размерности с помощью линейного слоя, чтобы совпадало с GPT-2\n",
    "            compressed_context_resized = torch.nn.Linear(compressed_context.size(-1), gpt2_model.config.hidden_size)(compressed_context_repeated)\n",
    "\n",
    "            # Сложение преобразованных тензоров\n",
    "            compressed_inputs_embeds = compressed_context_resized + gpt2_model.transformer.wte(compressed_inputs[\"input_ids\"])\n",
    "            compressed_outputs = gpt2_model(inputs_embeds=compressed_inputs_embeds, output_hidden_states=True).hidden_states[-1].mean(dim=1)\n",
    "\n",
    "            # compressed_loss = criterion(compressed_outputs, target_embedding)\n",
    "            # Используем combined_loss для оптимизации\n",
    "            loss = combined_loss(compressed_outputs, target_embedding, raw_context_embedding)\n",
    "\n",
    "            # Обновление оптимизатора только по скорректированным потерям\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            total_compressed_loss += loss.item()\n",
    "            count += 1\n",
    "\n",
    "            # Сохраняем текущую потерю для анализа изменения потерь\n",
    "            epoch_losses.append(loss.item())\n",
    "            example_loss_history[idx].append(loss.item())\n",
    "            # Сохранение примеров для диагностики\n",
    "            with torch.no_grad():\n",
    "                compressed_pred = predict_with_compressed_context(current_fragment, tokenizer, gpt2_model, device)\n",
    "                raw_pred = entry[\"raw_prediction\"]\n",
    "                fragment_pred = entry[\"fragment_prediction\"]\n",
    "\n",
    "                # Проверяем и обрабатываем compressed_context корректно перед декодированием\n",
    "                if compressed_context is not None and isinstance(compressed_context, torch.Tensor):\n",
    "                    # Пытаемся преобразовать в список токенов, исключая None\n",
    "                    compressed_tokens = [token for token in compressed_context.squeeze().tolist() if isinstance(token, (int, float)) and 0 <= token < tokenizer.vocab_size]\n",
    "\n",
    "                    if compressed_tokens:\n",
    "                        # Декодируем только корректные значения токенов\n",
    "                        compressed_context_text = tokenizer.decode(compressed_tokens)\n",
    "                    else:\n",
    "                        compressed_context_text = \"Empty or Invalid tokens found in compressed context\"\n",
    "                else:\n",
    "                    compressed_context_text = \"N/A\"\n",
    "\n",
    "                # Сохраняем примеры в отдельный список для всех примеров\n",
    "                examples_calculated.append(\n",
    "                    {\n",
    "                        \"context\": context,\n",
    "                        \"compressed_context\": compressed_context_text,\n",
    "                        \"current_fragment\": current_fragment,\n",
    "                        \"compressed_prediction\": compressed_pred,\n",
    "                        \"raw_prediction\": raw_pred,\n",
    "                        \"fragment_prediction\": fragment_pred,\n",
    "                        \"target\": tokenizer.decode(target_input[\"input_ids\"].squeeze().tolist()),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        # Анализ потерь между эпохами для вывода примеров с максимальным снижением потерь\n",
    "        if epoch > 0:\n",
    "            loss_reduction = [\n",
    "                (i, example_loss_history[i][-2] - example_loss_history[i][-1], examples_calculated[i][\"compressed_context\"], examples_calculated[i][\"compressed_prediction\"])\n",
    "                for i in range(len(epoch_losses))\n",
    "                if len(example_loss_history[i]) > 1\n",
    "            ]\n",
    "            loss_reduction.sort(key=lambda x: x[1], reverse=True)\n",
    "            top_examples = loss_reduction[:3]  # Три примера с максимальным снижением потерь\n",
    "        else:\n",
    "            top_examples = [\n",
    "                (i, 0, examples_calculated[i][\"compressed_context\"], examples_calculated[i][\"compressed_prediction\"]) for i in range(min(3, len(examples_calculated)))\n",
    "            ]  # Первые три примера для первой эпохи\n",
    "\n",
    "        avg_compressed_loss = total_compressed_loss / count if count > 0 else 0\n",
    "        avg_compression_ratio = total_compression_ratio / count if count > 0 else 0\n",
    "        avg_divergence = total_divergence / count if count > 0 else 0\n",
    "        raw_loss_values.append(raw_loss)\n",
    "        compressed_loss_values.append(avg_compressed_loss)\n",
    "        fragment_loss_values.append(fragment_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Avg Compressed Context Loss: {avg_compressed_loss:.4f}, Avg Compression Ratio: {avg_compression_ratio:.4f}, Avg Divergence: {avg_divergence:.4f}\")\n",
    "\n",
    "        # Обновление графика после каждой эпохи\n",
    "        update_loss_plot(loss_fig, epoch + 1, raw_loss, avg_compressed_loss, fragment_loss)\n",
    "\n",
    "        # Вывод примеров с максимальным снижением потерь\n",
    "        print(f\"\\n=== Примеры с максимальным снижением потерь после эпохи {epoch+1} ===\")\n",
    "        for idx, reduction, compressed_context, compressed_prediction in top_examples:\n",
    "            example = intermediate_data[idx]\n",
    "            print(f\"\\nПример {idx+1} (Снижение потерь: {reduction:.4f}):\")\n",
    "            print(f\"Предыстория: {example['context']}\")\n",
    "            print(f\"Сжатый контекст: {compressed_context}\")  # Используем сохраненный сжатый контекст\n",
    "            print(f\"Текущий фрагмент: {example['current_fragment']}\")\n",
    "            print(f\"Предсказание по сжатому контексту: {compressed_prediction}\")  # Используем сохраненное предсказание по сжатому контексту\n",
    "            print(f\"Предсказание по сырому контексту: {example['raw_prediction']}\")\n",
    "            print(f\"Предсказание по текущему фрагменту: {example['fragment_prediction']}\")\n",
    "            print(f\"Целевой текст: {example['target']}\")\n",
    "\n",
    "    return raw_loss_values, compressed_loss_values, fragment_loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Model file not found at context_optimizer2.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e812c9defe44a2ebfead4e4f6f2720e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines+markers',\n",
       "              'name': 'Raw Context Loss',\n",
       "              'type': 'scatter',\n",
       "              'uid': '408d0e58-61a6-4aab-94f6-55bac9469eec',\n",
       "              'x': [],\n",
       "              'y': []},\n",
       "             {'mode': 'lines+markers',\n",
       "              'name': 'Compressed Context Loss',\n",
       "              'type': 'scatter',\n",
       "              'uid': '51abc40e-73e0-4555-900f-e694e1d56ed0',\n",
       "              'x': [],\n",
       "              'y': []},\n",
       "             {'mode': 'lines+markers',\n",
       "              'name': 'Fragment Only Loss',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'e634a77d-ce54-4ceb-b8f3-39c7d9ba14be',\n",
       "              'x': [],\n",
       "              'y': []}],\n",
       "    'layout': {'template': '...',\n",
       "               'title': {'text': 'Графики потерь во время обучения'},\n",
       "               'xaxis': {'title': {'text': 'Эпоха'}},\n",
       "               'yaxis': {'title': {'text': 'Среднее значение потерь'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Epoch 1, Avg Compressed Context Loss: 12.4577, Avg Compression Ratio: 0.0000, Avg Divergence: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "Raw Context Loss",
         "type": "scatter",
         "uid": "408d0e58-61a6-4aab-94f6-55bac9469eec",
         "x": [
          1
         ],
         "y": [
          0.2385900616645813
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Compressed Context Loss",
         "type": "scatter",
         "uid": "51abc40e-73e0-4555-900f-e694e1d56ed0",
         "x": [
          1
         ],
         "y": [
          12.45771453102228
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Fragment Only Loss",
         "type": "scatter",
         "uid": "e634a77d-ce54-4ceb-b8f3-39c7d9ba14be",
         "x": [
          1
         ],
         "y": [
          0.27232280373573303
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Графики потерь во время обучения"
        },
        "xaxis": {
         "title": {
          "text": "Эпоха"
         }
        },
        "yaxis": {
         "title": {
          "text": "Среднее значение потерь"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Примеры с максимальным снижением потерь после эпохи 1 ===\n",
      "\n",
      "Пример 1 (Снижение потерь: 0.0000):\n",
      "Предыстория: = = Development = =\n",
      "Сжатый контекст: \"!!!!!!!!\"!!!!!\"!\n",
      "Текущий фрагмент: Concept work for Valkyria Chronicles III began after development finished on Valkyria Chronicles II in early 2010 , with full development beginning shortly after this . The director of Valkyria Chronicles II , Takeshi Ozawa , returned to that role for Valkyria Chronicles III . Development work took approximately one year . After the release of Valkyria Chronicles II , the staff took a look at both the popular response for the game and what they wanted to do next for the series . Like its predece\n",
      "Предсказание по сжатому контексту: Concept work for Valkyria Chronicles III began after development finished on Valkyria Chronicles II in early 2010, with full development beginning shortly after this. The director of Valkyria Chronicles II, Takeshi Ozawa, returned to that role for Valkyria Chronicles III. Development work took approximately one year. After the release of Valkyria Chronicles II, the staff took a look at both the popular response for the game and what they wanted to do next for the series. Like its predece..\n",
      "Предсказание по сырому контексту: \n",
      " \". Development Development = = theectria Chronicles 2. in the of. thealkyria Chronicles II. 2011 2011. and the development on in after the.\n",
      " game of developmentalkyria Chronicles III, Kazhi Kawa, was to the role in thealkyria Chronicles III in\n",
      " of on place two year to\n",
      " the completion of Valkyria Chronicles III, the game of over break at the the game and to the game and the the thought to do with. the game. The the predecessorilevelopased\n",
      "Предсказание по текущему фрагменту: .s is theFXria Chronicles 2: in the of. thealkyria Chronicles II. 2011 2013. and the support on in after the.\n",
      " game of thealkyria Chronicles III, Kazhi Kawa, was to the project in thealkyria Chronicles III in\n",
      " on on place two year to\n",
      " the completion of Valkyria Chronicles III, the game of over break at the the game and to the game and the the thought to do with. the game.\n",
      " the predecessorileceased\n",
      "Целевой текст: The majority of material created for previous games, such as the BLiTZ system and the design of maps, was carried over. Alongside this, improvements were made to the game's graphics and some elements were expanded, such as map layouts, mission structure, and the number of playable units per mission. A part of this upgrade involved creating unique polygon models for each character's body. In order to achieve this, the cooperative elements incorporated into the second game were removed\n",
      "\n",
      "Пример 2 (Снижение потерь: 0.0000):\n",
      "Предыстория: = = Reception = =\n",
      "Сжатый контекст: #\"\"#!#\"\"##!\"!!!!!#%!\n",
      "Текущий фрагмент: On its day of release in Japan , Valkyria Chronicles III topped both platform @-@ exclusive and multi @-@ platform sales charts . By early February , the game sold 102 @,@ 779 units , coming in second overall to The Last Story for the Wii . By the end of the year , the game had sold just over 152 @,@ 500 units .\n",
      "Предсказание по сжатому контексту: On its day of release in Japan, Valkyria Chronicles III topped both platform @-@ exclusive and multi @-@ platform sales charts. By early February, the game sold 102 @,@ 779 units, coming in second overall to The Last Story for the Wii. By the end of the year, the game had sold just over 152 @,@ 500 units.\n",
      "Предсказание по сырому контексту: \n",
      " \"gex. 0 0 = own = the = the. it =ries Chronicles 2: the charts and 1 and and to @--@ exclusive...\n",
      " comparison September, V game had over,- and and.,, and in at place behind the Legend of. the month U\n",
      " the end of the month, the game sold sold over over 1,,@ 7 units.\n",
      "\n",
      "Предсказание по текущему фрагменту:  the website, action, May, theiacria Chronicles 2: the the and and and and to @--platform exclusive...\n",
      " comparison October, V game had over,- and and.,, and in at place behind the Legend of. the month U\n",
      " the end of the month, V game sold sold over over 1,,@ 7 units.\n",
      "\n",
      "Целевой текст: Famitsu enjoyed the story, and were particularly pleased with the improvements to gameplay. Japanese gaming site Game Watch Impress, despite negatively noting its pacing and elements recycled from previous games, was generally positive about its story and characters, and found its gameplay entertaining despite off @-@ putting difficulty spikes. 4Gamer.net writer Naohiko Misuosame, in a \" Play Test \" article based on the game's PSN demo, felt that Valkyria Chronicles III provided a \" pro\n",
      "\n",
      "Пример 3 (Снижение потерь: 0.0000):\n",
      "Предыстория: On its day of release in Japan , Valkyria Chronicles III topped both platform @-@ exclusive and multi @-@ platform sales charts . By early February , the game sold 102 @,@ 779 units , coming in second overall to The Last Story for the Wii . By the end of the year , the game had sold just over 152 @,@ 500 units .\n",
      "Сжатый контекст: \"#!##$\"!#\"\"\"#%!\n",
      "Текущий фрагмент: Famitsu enjoyed the story , and were particularly pleased with the improvements to gameplay . Japanese gaming site Game Watch Impress , despite negatively noting its pacing and elements recycled from previous games , was generally positive about its story and characters , and found its gameplay entertaining despite off @-@ putting difficulty spikes . 4Gamer.net writer Naohiko Misuosame , in a \" Play Test \" article based on the game 's PSN demo , felt that Valkyria Chronicles III provided a \" pro\n",
      "Предсказание по сжатому контексту: Famitsu enjoyed the story, and were particularly pleased with the improvements to gameplay. Japanese gaming site Game Watch Impress, despite negatively noting its pacing and elements recycled from previous games, was generally positive about its story and characters, and found its gameplay entertaining despite off @-@ putting difficulty spikes. 4Gamer.net writer Naohiko Misuosame, in a \" Play Test \" article based on the game's PSN demo, felt that Valkyria Chronicles III provided a \" pro\n",
      "Предсказание по сырому контексту:  the website, action, May, theiacria Chronicles 2: the the and and and and to @--platform exclusive...\n",
      " comparison October, V game had over,- and and.,, and in at place behind the Legend of. the month U\n",
      " the end of the month, V game sold sold over over 1,,@ 7 units.\n",
      "itsu reported a game of and the able impressed with the game made the and\n",
      " publisher magazine FamSpot reportedpressions which its comparing the lack and the, from previous games, praised pleased pleased about the game and the. and was the story to. its--platforming the to.\n",
      "K alsocom, andokiiko Nakakihaki also who a recent positivethrough \" article, on the game, V gameplay Vita release, said that thealkyria Chronicles III was a \" good-\n",
      "Предсказание по текущему фрагменту: .ilies, a opportunity of but the very impressed with the story made the.\n",
      " fans culture KotFAQ haspressions which being reviewing the lack and pacing of from the games, has very pleased about the story and the. and was the story to. its- thetheing the on on\n",
      ". alsocom also andokiiko Kakiokaaki also who a reviewgoodthrough \" article, on the game, The story Vita,, said that thealkyria Chronicles 2 was a good fun-\n",
      "Целевой текст: PlayStation Official Magazine - UK praised the story's blurring of Gallia's moral standing, art style, and most points about its gameplay, positively noting the latter for both its continued quality and the tweaks to balance and content. Its one major criticism were multiple difficulty spikes, something that had affected the previous games. Heath Hindman of gaming website PlayStation Lifestyle praised the addition of non @-@ linear elements and improvements or removal of mechanics from V\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Epoch 2, Avg Compressed Context Loss: 11.5898, Avg Compression Ratio: 0.0000, Avg Divergence: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "Raw Context Loss",
         "type": "scatter",
         "uid": "408d0e58-61a6-4aab-94f6-55bac9469eec",
         "x": [
          1,
          2
         ],
         "y": [
          0.2385900616645813,
          0.2385900616645813
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Compressed Context Loss",
         "type": "scatter",
         "uid": "51abc40e-73e0-4555-900f-e694e1d56ed0",
         "x": [
          1,
          2
         ],
         "y": [
          12.45771453102228,
          11.589769820876533
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Fragment Only Loss",
         "type": "scatter",
         "uid": "e634a77d-ce54-4ceb-b8f3-39c7d9ba14be",
         "x": [
          1,
          2
         ],
         "y": [
          0.27232280373573303,
          0.27232280373573303
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Графики потерь во время обучения"
        },
        "xaxis": {
         "title": {
          "text": "Эпоха"
         }
        },
        "yaxis": {
         "title": {
          "text": "Среднее значение потерь"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Примеры с максимальным снижением потерь после эпохи 2 ===\n",
      "\n",
      "Пример 54 (Снижение потерь: 16.7909):\n",
      "Предыстория: = = = January – February = = =\n",
      "Сжатый контекст: !#$!#%\"&%\"!!&\"\"#\"(\n",
      "Текущий фрагмент: With the losing continuing , more rumors began to surface . Unlike before , the rumors were about player moves rather than coaching changes . The majority of rumors were that the Blue Jackets would trade Rick Nash . While Howson stated that he had never brought up trading Nash in discussions , other teams had inquired about his availability . Nash stated that if Columbus felt it would make the franchise better than he would be willing to waive his no @-@ trade clause . Howson publicly stated tha\n",
      "Предсказание по сжатому контексту: With the losing continuing, more rumors began to surface. Unlike before, the rumors were about player moves rather than coaching changes. The majority of rumors were that the Blue Jackets would trade Rick Nash. While Howson stated that he had never brought up trading Nash in discussions, other teams had inquired about his availability. Nash stated that if Columbus felt it would make the franchise better than he would be willing to waive his no @-@ trade clause. Howson publicly stated tha\n",
      "Предсказание по сырому контексту: \n",
      " \" = 1 February, March March Marchdraw exception team to the and are to circulate about The the, the rumors were not the's and than the moves. The rumors of the were about the team Jays would be for Nash to The thisie was that the was no heard Nash Nash Nash, the with How sources were been about him future. The was that he he wanted he was be sense trade better, it was, willing to trade his rights-tradetrade contract clause, Nashson stated stated that he\n",
      "Предсказание по текущему фрагменту:  the help team to the and have to circulate about The the, the team were not the's and than the moves. The rumors of the were about the team Jays would be for Nash to The thisie was that he was no heard Nash Nash Nash, the with How sources were been about him future.\n",
      " was that he he wanted he was be sense trade better, it was, willing to trade his rights-ntrade contract clause,\n",
      "son stated stated that he\n",
      "Целевой текст: At the halfway point of the season, with the Blue Jackets barely into double digit wins with an 11 – 25 – 5 record, worst in the league, and sitting 20 points out of playoff position, Columbus fired Arniel. He was replaced by Assistant Coach Todd Richards on an interim basis. Richards had previously coached the Minnesota Wild. He recorded his first coaching victory for the Blue Jackets in his second game, a 4 – 3 win over the Phoenix Coyotes. The change in coaching did not change the fo\n",
      "\n",
      "Пример 62 (Снижение потерь: 13.8036):\n",
      "Предыстория: Webb demonstrated his aggressiveness when he attempted to sortie on the first spring tide ( 30 May ) after taking command , but Atlanta 's forward engine broke down after he had passed the obstructions , and the ship ran aground . She was not damaged although it took over a day to pull her free . He planned to make another attempt on the next full tide , rejecting Mallory 's idea that he wait until the nearly complete ironclad Savannah was finished before his next sortie . In the meantime , Rear\n",
      "Сжатый контекст: #$\"#%!'&#!!\"!'!\"\"\"'\n",
      "Текущий фрагмент: In the early evening of 15 June , Webb began his next attempt by passing over the lower obstructions in the Wilmington River and spent the rest of the night coaling . He moved forward the next evening to a concealed position within easy reach of the monitors for an attack early the following morning . Webb planned to sink one of the monitors with his spar torpedo and then deal with the other one with his guns . The gunboat Isondiga and the tugboat Resolute were to accompany him to tow one or bot\n",
      "Предсказание по сжатому контексту: In the early evening of 15 June, Webb began his next attempt by passing over the lower obstructions in the Wilmington River and spent the rest of the night coaling. He moved forward the next evening to a concealed position within easy reach of the monitors for an attack early the following morning. Webb planned to sink one of the monitors with his spar torpedo and then deal with the other one with his guns. The gunboat Isondiga and the tugboat Resolute were to accompany him to tow one or bot\n",
      "Предсказание по сырому контексту:  have's that abilityiveness in he was to take out with the ground pitch game,a., and the a of but he'ss first was was down and a tried been the firstions. and the captain was aground.\n",
      " was rescued rescued, she was a a week to recover back back of\n",
      " was to sail a attempt to the second day day, but theory'ss offer of he would for the next full water- was was in before proceeding ship attemptie.\n",
      " the meantime, he Admiral- meantime morning of 30 May, the was to first sort on taking the the obstruct partions. the harbor Bay. then the next of the day iniling up He then on to next day and the position position on the reach of the Savannah, the attempt on in next morning. He's to make the of the monitors and his torpedo,, then attempt with the other with with his spar. He nextners wasabellai was the other- Stolute were also be him on the the of twohe\n",
      "Предсказание по текущему фрагменту:  the past days, July September, the and to journey day to flying through the bridge partions of the road area. passing the next of the day inoped up He then to and next day and the spot position in the reach of the bridge. the hour. in next morning.\n",
      " was to attack the of the monitors and his hammerring, then proceed with the other with with his spar. He nextners wasabellai was the other of Stolute were also be him. the him of twohe\n",
      "Целевой текст: A lookout aboard Weehawken spotted Atlanta at 04 : 10 on the morning of 17 June. When the latter ship closed to within about 1 @.@ 5 miles ( 2 @.@ 4 km ) of the two Union ships, she fired one round from her bow gun that passed over Weehawken and landed near Nahant. Shortly afterward, Atlanta ran aground on a sandbar ; she was briefly able to free herself, but the pressure of the tide pushed her back onto the sandbar. This time Webb was unable to get off and the monitors closed the range.\n",
      "\n",
      "Пример 6 (Снижение потерь: 12.8199):\n",
      "Предыстория: Valkyria Chronicles 3 was adapted into a two @-@ episode original video animation series in the same year of its release . Titled Senjō no Valkyria 3 : Taga Tame no Jūsō ( 戦場のヴァルキュリア３ 誰がための銃瘡 , lit . Valkyria of the Battlefield 3 : The Wound Taken for Someone 's Sake ) , it was originally released through PlayStation Network and Qriocity between April and May 2011 . The initially @-@ planned release and availability period needed to be extended due to a stoppage to PSN during the early summer of\n",
      "Сжатый контекст: %#\"%%\"\"!!\"%$\"#\n",
      "Текущий фрагмент: The anime 's title was inspired by the principle purpose of the Nameless : to suffer in battle for the goals of others . A subtitle attached to the project during development was \" The Road to Kubinka \" , which referenced the Kubinka Tank Museum in Moscow . The game 's main theme was how the characters regained their sense of self when stripped of their names and identities , along with general themes focused on war and its consequences . While making the anime , the production team were told by\n",
      "Предсказание по сжатому контексту: The anime's title was inspired by the principle purpose of the Nameless : to suffer in battle for the goals of others. A subtitle attached to the project during development was \" The Road to Kubinka \", which referenced the Kubinka Tank Museum in Moscow. The game's main theme was how the characters regained their sense of self when stripped of their names and identities, along with general themes focused on war and its consequences. While making the anime, the production team were told by\n",
      "Предсказание по сырому контексту: .ria Chronicles 4 Chronicles a into a game-3hour format.. game.. the early year. the release. Theles \"ranou no Kalkyria Chronicles: Theō noō, Kikanjō, The��豴��ントーーー,��,����り�、���ぴ�, Sen. \"alkyria Chronicles the V) ) V Battleounded of ) the'ss Sake ), the was released released in the Network in wasVCar in January and June of. It series released-@ episode for date the dates were to be adjusted to to the lackage in theN's the summer stages of 2012 Witcher'ss second's cancelled by the Japanese of of the gameco Kingdom The be from the. the sake of the. The new for to the video stated the was \" Sen W to Vo \", which was the storyinka Saga Battle in Japan. The title wass title character was the the world of their lost of self and they of their armor and identities. and with the feelings of on the and the aftermath. The the the game, the project team also also that the\n",
      "Предсказание по текущему фрагменту: \n",
      "'sThe first character originally by the Japanese of of the animeeless One to be from the, the sake of the. The character for to the anime stated the was \" The Nam to theo \", which was the Naminka- Battle in Japan. The title wass story character was the the Nam would their humanity of self- they of their armor and identities. and with the feelings of on the and the aftermath.\n",
      " the the game, the team team also also that the\n",
      "Целевой текст: Two manga adaptations were produced, following each of the game's main female protagonists Imca and Riela. They were Senjō no Valkyria 3 : Namo naki Chikai no Hana ( 戦場のヴァルキュリア3 名もなき誓いの花, lit. Valkyria of the Battlefield 3 : The Flower of the Nameless Oath ), illustrated by Naoyuki Fujisawa and eventually released in two volumes after being serialized in Dengeki Maoh between 2011 and 2012 ; and Senjō no Valkyria 3 : -Akaki Unmei no Ikusa Otome- ( 戦場のヴァルキュリア3 -赤き運命の戦乙女-, lit. Valkyria of\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Epoch 3, Avg Compressed Context Loss: 11.7269, Avg Compression Ratio: 0.0000, Avg Divergence: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "Raw Context Loss",
         "type": "scatter",
         "uid": "408d0e58-61a6-4aab-94f6-55bac9469eec",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Compressed Context Loss",
         "type": "scatter",
         "uid": "51abc40e-73e0-4555-900f-e694e1d56ed0",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          12.45771453102228,
          11.589769820876533,
          11.72688073918299
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Fragment Only Loss",
         "type": "scatter",
         "uid": "e634a77d-ce54-4ceb-b8f3-39c7d9ba14be",
         "x": [
          1,
          2,
          3
         ],
         "y": [
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Графики потерь во время обучения"
        },
        "xaxis": {
         "title": {
          "text": "Эпоха"
         }
        },
        "yaxis": {
         "title": {
          "text": "Среднее значение потерь"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Примеры с максимальным снижением потерь после эпохи 3 ===\n",
      "\n",
      "Пример 33 (Снижение потерь: 11.8992):\n",
      "Предыстория: Child Thoughts in Picture and Verse ( by M. K. Westcott ) ; Blackie , 1925\n",
      "Сжатый контекст: &#!$$!#\"%\"\"%!\"\"!!\n",
      "Текущий фрагмент: Flower Fairies of the Autumn ; Blackie , 1926\n",
      "Предсказание по сжатому контексту: Flower Fairies of the Autumn ; Blackie, 1926\n",
      "Предсказание по сырому контексту: ,\n",
      " the Frames Video\n",
      "19 David.A. K ) )\n",
      "\n",
      " and, J ;ing, ( the World ( Blackie, 1925 Flower\n",
      "Предсказание по текущему фрагменту: .inging\n",
      " the World\n",
      " and and's by.\n",
      "Целевой текст: Summer Songs with Music ; Blackie, 1926\n",
      "\n",
      "Пример 125 (Снижение потерь: 8.2535):\n",
      "Предыстория: = = War years = =\n",
      "Сжатый контекст: $\"%$!!\"#!!!$#&!\"!\n",
      "Текущий фрагмент: The gold dollar continued to be produced in the late 1850s , though mintages declined from the figures of two million or more each year between 1850 and 1854 . Only about 51 @,@ 000 gold dollars were produced in 1860 , with over two @-@ thirds of that figure at Philadelphia , just under a third at San Francisco , and 1 @,@ 566 at Dahlonega . Roughly a hundred are known of the last , creating one of the great rarities from Dahlonega in the series .\n",
      "Предсказание по сжатому контексту: The gold dollar continued to be produced in the late 1850s, though mintages declined from the figures of two million or more each year between 1850 and 1854. Only about 51 @,@ 000 gold dollars were produced in 1860, with over two @-@ thirds of that figure at Philadelphia, just under a third at San Francisco, and 1 @,@ 566 at Dahlonega. Roughly a hundred are known of the last, creating one of the great rarities from Dahlonega in the series. year year 35\n",
      "Предсказание по сырому контексту: \n",
      " \"frame, = = war standard is to rise the in the United 19s. and iting were. about mid of 18 to to more in year to 18 and 190055. The in one percent $000 and of dollars were produced in the, and the half million 000 000 000 of the being being the. and before the quarter of New Francisco. and a/-@ 1 000 dollars Newgrenga. Thely half quarter dollars still to the gold two and a hundred the largest goldiftsities of theonega. the late. The\n",
      "Предсказание по текущему фрагменту: \n",
      " standard is to rise the in the United 19s and and ited were. about late of 18 to to more in year. 18 and 1855. The in one, $000, of dollars were produced in the, and the 100 million 000 000 000 of the being being the. and a the million of New Francisco. and a.-@ 1000 000 dollars Newgrenga. Thely half quarter dollars produced to the gold two and a of the largest goldiftsities of theonega. the early.\n",
      "\n",
      "Целевой текст: The other candidate for the rarest from that mint is the 1861 @-@ D, with an estimated mintage of 1 @,@ 000 and perhaps 45 to 60 known. Two pairs of dies were shipped from Philadelphia to Dahlonega on December 10, 1860 ; they arrived on January 7, 1861, two weeks before Georgia voted to secede from the Union, as the American Civil War began. Under orders from Governor Joseph E. Brown, state militia secured the mint, and at some point, small quantities of dollars and half eagles were pr\n",
      "\n",
      "Пример 135 (Снижение потерь: 7.9684):\n",
      "Предыстория: = = = Zapata in south and central Mexico = = =\n",
      "Сжатый контекст: \"%%\"\"$!!!$!#'\n",
      "Текущий фрагмент: At about the same time that Villa and Orozco were marching on Ciudad Juárez , the Zapatista revolt gathered strength and spread to the states of Puebla , Tlaxcala , Mexico , Michoacán and Guerrero . On April 14 , Madero had Emiliano Zapata officially designated as his representative in the region . However , Zapata was worried that if he did not fully control all the major towns in Morelos by the time that Madero concluded negotiations with Díaz , the demands of his agrarian movement and the iss\n",
      "Предсказание по сжатому контексту: At about the same time that Villa and Orozco were marching on Ciudad Juárez, the Zapatista revolt gathered strength and spread to the states of Puebla, Tlaxcala, Mexico, Michoacán and Guerrero. On April 14, Madero had Emiliano Zapata officially designated as his representative in the region. However, Zapata was worried that if he did not fully control all the major towns in Morelos by the time that Madero concluded negotiations with Díaz, the demands of his agrarian movement and the iss\n",
      "Предсказание по сырому контексту: \n",
      " \" =ier_ the- east Mexico. = = =oll the same time as the Rica hiszco were killed to theudad Juarezrez. the Zapatistas forces was in in the to the rest of Chiuebla and Chiamaaxcala, and and andoacán, Chi.\n",
      " the 1, theuro and beenio Zapata, declared as the successor in the Mexican. On, theata had not that the he did not take cooperate the of territory cities in thelos, April end he heero was his with theomingaz, he Zap of the peoplerarian revolution would the Zapu\n",
      "Предсказание по текущему фрагменту:  the the same time, the was hiszco were in toward theudad Juarezrez, the cityatista Army was momentum in the to the city of Chiuebla and Chiamaaxcala, and City andoacán, Chi.\n",
      " the 18, theuro and beenio Aguata, declared as the successor in the Congress.\n",
      ", theata was not that the he did not take cooperate the of territories cities in thelos, April end he heero was his with theomingaz, he Zap of the peoplerarian revolution would the Zapu\n",
      "Целевой текст: Zapata began the attack on Cuautla on May 13 with 4000 troops against 400 elite soldiers of the so @-@ called \" Golden Fifth \" ; the Fifth Cavalry Regiment of the Federal Army. The battle took almost a week and has been described as \" six of the most terrible days of battle in the whole Revolution \". It consisted of house to house fighting, hand @-@ to @-@ hand combat, and no quarter given by either side. General Victoriano Huerta arrived in nearby Cuernavaca with 600 reinforcements, but d\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Epoch 4, Avg Compressed Context Loss: 10.8929, Avg Compression Ratio: 0.0000, Avg Divergence: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "Raw Context Loss",
         "type": "scatter",
         "uid": "408d0e58-61a6-4aab-94f6-55bac9469eec",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Compressed Context Loss",
         "type": "scatter",
         "uid": "51abc40e-73e0-4555-900f-e694e1d56ed0",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          12.45771453102228,
          11.589769820876533,
          11.72688073918299,
          10.892910257813893
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Fragment Only Loss",
         "type": "scatter",
         "uid": "e634a77d-ce54-4ceb-b8f3-39c7d9ba14be",
         "x": [
          1,
          2,
          3,
          4
         ],
         "y": [
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Графики потерь во время обучения"
        },
        "xaxis": {
         "title": {
          "text": "Эпоха"
         }
        },
        "yaxis": {
         "title": {
          "text": "Среднее значение потерь"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Примеры с максимальным снижением потерь после эпохи 4 ===\n",
      "\n",
      "Пример 172 (Снижение потерь: 14.3913):\n",
      "Предыстория: Fey is known for her deadpan humor and delivery ; her \" sardonic wit \" has become a trademark of hers , upon which several critics have commented in their reviews of Fey 's work . According to Los Angeles Times critic Mary McNamara , Fey \" project [ s ] both oblivious security and hyper @-@ alert insecurity with the same expression \" in her performances , while The Chronicle 's Dillon Fernando wrote that the actress specializes in \" delectable , situational and ironic comedy \" . On Fey 's comedi\n",
      "Сжатый контекст: \"!!!#!$!%\"!$\"\n",
      "Текущий фрагмент: Seldom hesitating to use herself as the butt of her own jokes , Fey is also well known for practicing self @-@ deprecating humor , as demonstrated throughout her performance as Liz Lemon in 30 Rock . In an article ranking Fey 's six greatest jokes , David Renshaw of The Guardian wrote that the performer 's work continues to feature her \" trademark mix of snark , self @-@ deprecation and pop @-@ culture smarts . \" Fey 's self @-@ deprecating comedic style inspired Ashley Fetters of The Atlantic t\n",
      "Предсказание по сжатому контексту: Seldom hesitating to use herself as the butt of her own jokes, Fey is also well known for practicing self @-@ deprecating humor, as demonstrated throughout her performance as Liz Lemon in 30 Rock. In an article ranking Fey's six greatest jokes, David Renshaw of The Guardian wrote that the performer's work continues to feature her \" trademark mix of snark, self @-@ deprecation and pop @-@ culture smarts. \" Fey's self @-@ deprecating comedic style inspired Ashley Fetters of The Atlantic t 58 58 58\n",
      "Предсказание по сырому контексту: ., a for his workpan, and her, she voice'\"onic\"\" is been a staple of her. and which she of have pointed. the reviews. her's s work.\n",
      " to the Angeles Times writer Robert Annamara, \"'s hasedher ] \" aness and a-#$conscious-ness. her same \" of'her voice. and also New ofs David D has that \" \" \" in \" aviousable \" \" humor often \".\".\n",
      " the's websiteical-infeld Seenitating to make the as a \" of jokes jokes jokes, she has known known known for her her-- @ingrecation her. and well by her work of the Lemon in the Rock.\n",
      " her interview for Fey's performance best performances, The F.haw wrote the New wrote that \" actress \"s \" \" to be in as as humor of humorarky sarc--@ andrecating and humor culture-@ humor.\"s.\" \"\n",
      "'s work @-@ deprecation humor style is her Juddzer, The New,.\n",
      "Предсказание по текущему фрагменту: . doitating to take the as a \" of jokes own jokes, she's a a aware for her her-sexpression-recation her. and well by her career in the in in the Rock.\n",
      " the interview for her'ss performance best comedic, she Simon.haw wrote The New wrote: Fey comedian \"s \" \" to be in asas \" of humorarky sarc-- @ andrecating and humor culture-@ self.\"s.\" '\n",
      "'ss humor @-@ deprecation humor style is her Juddzer to The New toumblr\n",
      "Целевой текст: As an actress, Fey has developed a reputation for portraying \" the hilarious, self @-@ deprecating unmarried career woman \" in most of her films to @-@ date. The Boston Globe's Janice Paige defended her limited filmography by writing that, unlike most film actors, Fey remains \" realistic about her range as a leading lady and says she ’ s been deliberate about only taking on parts for which she actually seems suited. \" Fey explained that she approaches each role asking herself, \" Would I\n",
      "\n",
      "Пример 80 (Снижение потерь: 9.6709):\n",
      "Предыстория: = = Design = =\n",
      "Сжатый контекст: !$\"\"!#\"!###\"\"\"\n",
      "Текущий фрагмент: Erzherzog Ferdinand Max displaced 10 @,@ 472 long tons ( 10 @,@ 640 t ) . She was 414 feet 2 inches ( 126 @.@ 2 m ) long , had a beam of 71 feet 5 inches ( 21 @.@ 8 m ) and a draft of 24 feet 7 inches ( 7 @.@ 5 m ) . She was manned by 700 men . She and her sisters were the last and largest pre @-@ dreadnought class built by the Austro @-@ Hungarian Navy , surpassing the Habsburg class by approximately 2 @,@ 000 tonnes ( 1 @,@ 968 long tons ) . She was propelled by two two @-@ shaft , four cylind\n",
      "Предсказание по сжатому контексту: Erzherzog Ferdinand Max displaced 10 @,@ 472 long tons ( 10 @,@ 640 t ). She was 414 feet 2 inches ( 126 @.@ 2 m ) long, had a beam of 71 feet 5 inches ( 21 @.@ 8 m ) and a draft of 24 feet 7 inches ( 7 @.@ 5 m ). She was manned by 700 men. She and her sisters were the last and largest pre @-@ dreadnought class built by the Austro @-@ Hungarian Navy, surpassing the Habsburg class by approximately 2 @,@ 000 tonnes ( 1 @,@ 968 long tons ). She was propelled by two two @-@ shaft, four cylind......\n",
      "Предсказание по сырому контексту: \n",
      " \". Design Designg = = = =,imil =,max = =, @ @ =1 ),@ 4 ) ) = =lled a ft long inches long 1., ) 4, ).. and a length of 4 feet ( inches ( 6 @.@ 2 m ) long a beam of 1 feet ( inches ( 21 @.@ 2 m ). She was a by a men and She was her crew were the first of only of-,war-naught to of. the Germanro--N- Navy. anding the original.burgs. a 1,,@ 1 tons. 1,,@ 1 m t tons ). She was the by a 8-, @ gunss one @indrical\n",
      "Предсказание по текущему фрагменту: .,,,,,imil by,G 2,,,, of1.,@ 4 long) @. was a. tall inches tall 1., ) 6, ).. and a total of 6 feet ( inches ( 6 @.@ 2 m ). a beam of 1 feet ( inches ( 9 @.@ 2 m ). She was a by a men and\n",
      " was her crew were the first of only of-,war-nough to of in the Uro--N Aust Navy. anding the original.burgs. a 1,,@ 1 tons ( 1,,@ 1 m t tons ). She was the by a 8-, @ gunss one @indrical\n",
      "Целевой текст: Erzherzog Ferdinand Max carried a primary armament of four 24 @-@ centimeter ( 9 @.@ 4 in ) / 40 caliber guns in two twin turrets on the centerline. These guns were an Austro @-@ Hungarian replica of the British 24 cm / 40 ( 9 @.@ 4 \" ) Krupp C / 94, which was used on the Habsburgs. Her secondary armament consisted of twelve 19 @-@ centimeter ( 7 @.@ 5 in ) / 42 caliber guns, also made by Škoda, mounted in eight single casemates on either wing of the ship and two twin turrets on the centerl\n",
      "\n",
      "Пример 95 (Снижение потерь: 8.3737):\n",
      "Предыстория: Scholars have long debated whether traditional Egyptian religion ever asserted that the multiple gods were , on a deeper level , unified . Reasons for this debate include the practice of syncretism , which might suggest that all the separate gods could ultimately merge into one , and the tendency of Egyptian texts to credit a particular god with power that surpasses all other deities . Another point of contention is the appearance of the word \" god \" in wisdom literature , where the term does no\n",
      "Сжатый контекст: $#!!!##!#\"!!!\n",
      "Текущий фрагмент: In 1971 , Erik Hornung published a study rebutting these views . He points out that in any given period many deities , even minor ones , were described as superior to all others . He also argues that the unspecified \" god \" in the wisdom texts is a generic term for whichever deity the reader chooses to revere . Although the combinations , manifestations , and iconographies of each god were constantly shifting , they were always restricted to a finite number of forms , never becoming fully interc\n",
      "Предсказание по сжатому контексту: In 1971, Erik Hornung published a study rebutting these views. He points out that in any given period many deities, even minor ones, were described as superior to all others. He also argues that the unspecified \" god \" in the wisdom texts is a generic term for whichever deity the reader chooses to revere. Although the combinations, manifestations, and iconographies of each god were constantly shifting, they were always restricted to a finite number of forms, never becoming fully interc.,,\n",
      "Предсказание по сырому контексту: .hip found known whether the wisdom religion was existed itself it gods gods were the or the level level, the. The for this are include the fact of theretism, which is have that the gods gods gods were be be into one. or the belief to the religion to emphasize the single god with the over wases that others gods.\n",
      " possibility of contention is that idea of a god \"god,\" in the texts. which it word is not more the, the Jbl, a book ofutting the claims. In argued out that the the case book of different were including those ones, were associated as \" to the others. In also points that the term \" god \" in the Egyptian literature is not reference term for a deity was texts is to identifyre.\n",
      " the term of or, and namesography of the deity are not changing, the were not the to a single number of deities. and to a unifiedwou\n",
      "Предсказание по текущему фрагменту:  the, the J,, a book inutting the claims. He found out that the the case year of of have including those ones, are not as having to the other. He also points that the \" \"great \" was the Bible of of not \" term for a deity was author is to believere.\n",
      " Horn study of and, and descriptionsography of these deity are not changing, the were not the to a single number of deities. and to a completewou\n",
      "Целевой текст: Hornung's arguments have greatly influenced other scholars of Egyptian religion, but some still believe that at times the gods were more unified than he allows. Jan Assmann maintains that the notion of a single deity developed slowly through the New Kingdom, beginning with a focus on Amun @-@ Ra as the all @-@ important sun god. In his view, Atenism was an extreme outgrowth of this trend. It equated the single deity with the sun and dismissed all other gods. Then, in the backlash agains\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Epoch 5, Avg Compressed Context Loss: 11.1516, Avg Compression Ratio: 0.0000, Avg Divergence: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "Raw Context Loss",
         "type": "scatter",
         "uid": "408d0e58-61a6-4aab-94f6-55bac9469eec",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "y": [
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Compressed Context Loss",
         "type": "scatter",
         "uid": "51abc40e-73e0-4555-900f-e694e1d56ed0",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "y": [
          12.45771453102228,
          11.589769820876533,
          11.72688073918299,
          10.892910257813893,
          11.151580595122981
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Fragment Only Loss",
         "type": "scatter",
         "uid": "e634a77d-ce54-4ceb-b8f3-39c7d9ba14be",
         "x": [
          1,
          2,
          3,
          4,
          5
         ],
         "y": [
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Графики потерь во время обучения"
        },
        "xaxis": {
         "title": {
          "text": "Эпоха"
         }
        },
        "yaxis": {
         "title": {
          "text": "Среднее значение потерь"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Примеры с максимальным снижением потерь после эпохи 5 ===\n",
      "\n",
      "Пример 165 (Снижение потерь: 9.9770):\n",
      "Предыстория: In 2002 , Fey appeared in the surreal comedy Martin & Orloff . She made her debut as writer and co @-@ star of the 2004 teen comedy Mean Girls . Characters and behaviors in the movie are based on Fey 's high school life at Upper Darby High School and on the non @-@ fiction book Queen Bees and Wannabes by Rosalind Wiseman . The cast includes other past cast members of SNL including Tim Meadows , Ana Gasteyer , and Amy Poehler . The film received favorable reviews , and was a box office success ,\n",
      "Сжатый контекст: \"\"#\"\"\"\"\"#$\"\"\"\n",
      "Текущий фрагмент: In a 2004 interview , Fey expressed that she would like to write and direct movies . In 2006 , Fey worked on a movie script for Paramount Pictures , which was to feature Sacha Baron Cohen , by the name of Curly Oxide and Vic Thrill , based loosely on the true story of a Hasidic rock musician . In 2007 , she was cast in the animated comedy film Aqua Teen Hunger Force Colon Movie Film for Theaters as the Aqua Teens ' mother , a giant burrito .\n",
      "Предсказание по сжатому контексту: In a 2004 interview, Fey expressed that she would like to write and direct movies. In 2006, Fey worked on a movie script for Paramount Pictures, which was to feature Sacha Baron Cohen, by the name of Curly Oxide and Vic Thrill, based loosely on the true story of a Hasidic rock musician. In 2007, she was cast in the animated comedy film Aqua Teen Hunger Force Colon Movie Film for Theaters as the Aqua Teens'mother, a giant burrito.\n",
      "Предсказание по сырому контексту:  the, theer in a filmist \" Sc Kramersonoff, In was her first in a- director-nwriter- on the show film comedy, Girls. She include characters were the show were described on her'ss own school years. the Westby High School. her her character--existent character of she of. theivesabes. theieind Seman.\n",
      " film includes: notable and members such theL,: Allen, Bill Marieoner, and Michael Poehler.\n",
      " film was a reviews from including Fey nominated critical office hit. with 2005 recent interview with Fey said her she was like to see a direct a that She 2005, she was on the film called for the Pictures. which she released be aa Baron Cohen as who the same of \"b.ley. the Mensush. and on on the novel story of a youngidic Jew band who Fey 2007, Fey appeared nominated in the film comedy The The Teen Hunger Force,ization. by the Weinstein. a lead Teenens.s. who character squidly- In\n",
      "Предсказание по текущему фрагменту:  the statement interview with heer concern he was not to see a direct a about \" a, she said on a film called for the Pictures that which she based be aa Baron Cohen as who the same of \"b.ley. wasenteushers which on on the novel story of a youngidic Jew band who The 2009, Fey was hired as the role film series The Teen Hunger Force,ization,, the CW. a tit Teenens.s. who character,ly- In\n",
      "Целевой текст: She received her SAG card after appearing in Artie Lange's Beer League released in 2006, in which she was compelled to join for \"... a thousand dollars \".\n",
      "\n",
      "Пример 108 (Снижение потерь: 6.2423):\n",
      "Предыстория: = = = Sports = = =\n",
      "Сжатый контекст: \"!!!\"###!#!!\n",
      "Текущий фрагмент: Competitive gliding in the UK takes place between May and September . Regionals are local competitions , organised and run by one of the bigger gliding clubs in the region , and represent the entry level to glider racing . Races are handicapped according to glider performance , and normally take place over nine days . Success in the regionals allows pilots to progress to the nationals , where there are five classes of competition . These are based on glider performance , the lowest being club cl\n",
      "Предсказание по сжатому контексту: Competitive gliding in the UK takes place between May and September. Regionals are local competitions, organised and run by one of the bigger gliding clubs in the region, and represent the entry level to glider racing. Races are handicapped according to glider performance, and normally take place over nine days. Success in the regionals allows pilots to progress to the nationals, where there are five classes of competition. These are based on glider performance, the lowest being club cl..,.\n",
      "Предсказание по сырому контексту: \n",
      " \" =. = = = = = = the water is place in the and June. Theals are held to where and by run by the or the UK teamsiders clubs in the UK. the are the best level of theiding racing in\n",
      " are heldapped by to theider speed and and are take place in a days.\n",
      "ful a raceals is the to compete to the next and and they are no days of gl.\n",
      " are: on theider performance, and ability level the levelocked\n",
      "Предсказание по текущему фрагменту: .,iding is the open is place in the and June,\n",
      "ally are held to that where by run by the of the UK companiesiders companies in the UK. the are the best level of theiding racing in\n",
      " are heldapped by to theider speed and and are take place in a days.\n",
      "ful the raceals is you to compete to the next and and they are no days of gl.\n",
      " are: on theider performance, and ability level the levelocked\n",
      "Целевой текст: Handicapped air racing is open to any propeller @-@ driven aircraft capable of maintaining a minimum speed of 100 miles ( 160 km ) per hour in level flight. Races are a case of \" fly low, fly fast, turn left \", consisting of 4 – 5 laps round a 20 – 25 mile ( 32 – 40 km ) circuit. Faster aircraft are handicapped by starting after slower aircraft, the intention being that the race concludes with all aircraft diving for the finish line together. There are up to 16 races per year, conducted\n",
      "\n",
      "Пример 5 (Снижение потерь: 6.1959):\n",
      "Предыстория: = = = Adaptations = = =\n",
      "Сжатый контекст: !!!!!!#!\"&$!#!!\n",
      "Текущий фрагмент: Valkyria Chronicles 3 was adapted into a two @-@ episode original video animation series in the same year of its release . Titled Senjō no Valkyria 3 : Taga Tame no Jūsō ( 戦場のヴァルキュリア３ 誰がための銃瘡 , lit . Valkyria of the Battlefield 3 : The Wound Taken for Someone 's Sake ) , it was originally released through PlayStation Network and Qriocity between April and May 2011 . The initially @-@ planned release and availability period needed to be extended due to a stoppage to PSN during the early summer of\n",
      "Предсказание по сжатому контексту: Valkyria Chronicles 3 was adapted into a two @-@ episode original video animation series in the same year of its release. Titled Senjō no Valkyria 3 : Taga Tame no Jūsō ( 戦場のヴァルキュリア３ 誰がための銃瘡, lit. Valkyria of the Battlefield 3 : The Wound Taken for Someone's Sake ), it was originally released through PlayStation Network and Qriocity between April and May 2011. The initially @-@ planned release and availability period needed to be extended due to a stoppage to PSN during the early summer of\n",
      "Предсказание по сырому контексту: \n",
      " \" =ive. = = =ectries = = = released to a game--player game.. game.. which form year. the release. Theles \"ranou no Kalkyria Chronicles: Sensub noaga, Kikanjō no The��籴��ントーーー,�� )����り�て��ぴ� ) Sen. \"alkyria Chronicles the V) ) V Battleounded of ) the'ss Sake ) was the was the released in the Network in wasVCar in January and June of. It series released-@ episode for date the dates were to be adjusted to to the lackage in theN's the summer stages of 2011\n",
      "Предсказание по текущему фрагменту: .ria Chronicles 4 Chronicles a into a game-3hour format.. game.. the early year. the release. Theles \"ranou no Kalkyria Chronicles: Theō noō, Kikanjō, The��豴��ントーーー,��,����り�、���ぴ�, Sen. \"alkyria Chronicles the V) ) V Battleounded of ) the'ss Sake ), the was released released in the Network in wasVCar in January and June of. It series released-@ episode for date the dates were to be adjusted to to the lackage in theN's the summer stages of 2012\n",
      "Целевой текст: The anime's title was inspired by the principle purpose of the Nameless : to suffer in battle for the goals of others. A subtitle attached to the project during development was \" The Road to Kubinka \", which referenced the Kubinka Tank Museum in Moscow. The game's main theme was how the characters regained their sense of self when stripped of their names and identities, along with general themes focused on war and its consequences. While making the anime, the production team were told by\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Epoch 6, Avg Compressed Context Loss: 11.1435, Avg Compression Ratio: 0.0000, Avg Divergence: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "Raw Context Loss",
         "type": "scatter",
         "uid": "408d0e58-61a6-4aab-94f6-55bac9469eec",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Compressed Context Loss",
         "type": "scatter",
         "uid": "51abc40e-73e0-4555-900f-e694e1d56ed0",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          12.45771453102228,
          11.589769820876533,
          11.72688073918299,
          10.892910257813893,
          11.151580595122981,
          11.143476815393129
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Fragment Only Loss",
         "type": "scatter",
         "uid": "e634a77d-ce54-4ceb-b8f3-39c7d9ba14be",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6
         ],
         "y": [
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Графики потерь во время обучения"
        },
        "xaxis": {
         "title": {
          "text": "Эпоха"
         }
        },
        "yaxis": {
         "title": {
          "text": "Среднее значение потерь"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Примеры с максимальным снижением потерь после эпохи 6 ===\n",
      "\n",
      "Пример 89 (Снижение потерь: 15.4657):\n",
      "Предыстория: Divine behavior was believed to govern all of nature . Except for the few deities who disrupted the divine order , the gods ' actions maintained maat and created and sustained all living things . They did this work using a force the Egyptians called heka , a term usually translated as \" magic \" . Heka was a fundamental power that the creator god used to form the world and the gods themselves .\n",
      "Сжатый контекст: $!!!\"\"\"$\"#!\"!!\n",
      "Текущий фрагмент: The gods ' actions in the present are described and praised in hymns and funerary texts . In contrast , mythology mainly concerns the gods ' actions during a vaguely imagined past in which the gods were present on earth and interacted directly with humans . The events of this past time set the pattern for the events of the present . Periodic occurrences were tied to events in the mythic past ; the succession of each new pharaoh , for instance , reenacted Horus ' accession to the throne of his fa\n",
      "Предсказание по сжатому контексту: The gods'actions in the present are described and praised in hymns and funerary texts. In contrast, mythology mainly concerns the gods'actions during a vaguely imagined past in which the gods were present on earth and interacted directly with humans. The events of this past time set the pattern for the events of the present. Periodic occurrences were tied to events in the mythic past ; the succession of each new pharaoh, for instance, reenacted Horus'accession to the throne of his fa\n",
      "Предсказание по сырому контексту: ., is not to be the human the,. for the most animals who were the natural order, the rest were were were the-'were the maintained the of things.\n",
      " were not by in the variety called size call the-, which force for used as \"force.\" or Theka was a powerful element that was Egyptians of of to control the world around the gods used. The he were actions were the world day not in described by themns and hyary texts. The the to the and focuses the gods'actions in the time defined time. which they gods were not and the. the with with the. The gods of the past are are the stage for the gods of the present. Theically references of also to the in the pastological world. the gods of gods god eventaraoh's the example, was-acted the'sion to the throne of Horus fathererie\n",
      "Предсказание по текущему фрагменту: \n",
      " ofhave'the world day not in the by themns and hyary songs.. the to the is focuses the gods and actions in the time defined time. which the gods are not and the. the with with the. The gods of the past are are the stage for the gods of the present. Theic references of also to the in the pastological world. the gods of events of eventaraoh's the example, was-acted the' actionsion to the throne of the fathererie\n",
      "Целевой текст: In myth, the gods behave much like humans. They feel emotion ; they can eat, drink, fight, weep, sicken, and die. Some have unique character traits. Set is aggressive and impulsive, and Thoth, patron of writing and knowledge, is prone to long @-@ winded speeches. Yet overall, the gods are more like archetypes than well drawn characters. Their behavior is inconsistent, and their thoughts and motivations are rarely stated. Most myths about them lack highly developed characters and\n",
      "\n",
      "Пример 95 (Снижение потерь: 9.1151):\n",
      "Предыстория: Scholars have long debated whether traditional Egyptian religion ever asserted that the multiple gods were , on a deeper level , unified . Reasons for this debate include the practice of syncretism , which might suggest that all the separate gods could ultimately merge into one , and the tendency of Egyptian texts to credit a particular god with power that surpasses all other deities . Another point of contention is the appearance of the word \" god \" in wisdom literature , where the term does no\n",
      "Сжатый контекст: %!!%!$####\"!\"\n",
      "Текущий фрагмент: In 1971 , Erik Hornung published a study rebutting these views . He points out that in any given period many deities , even minor ones , were described as superior to all others . He also argues that the unspecified \" god \" in the wisdom texts is a generic term for whichever deity the reader chooses to revere . Although the combinations , manifestations , and iconographies of each god were constantly shifting , they were always restricted to a finite number of forms , never becoming fully interc\n",
      "Предсказание по сжатому контексту: In 1971, Erik Hornung published a study rebutting these views. He points out that in any given period many deities, even minor ones, were described as superior to all others. He also argues that the unspecified \" god \" in the wisdom texts is a generic term for whichever deity the reader chooses to revere. Although the combinations, manifestations, and iconographies of each god were constantly shifting, they were always restricted to a finite number of forms, never becoming fully interc.,,\n",
      "Предсказание по сырому контексту: .hip found known whether the wisdom religion was existed itself it gods gods were the or the level level, the. The for this are include the fact of theretism, which is have that the gods gods gods were be be into one. or the belief to the religion to emphasize the single god with the over wases that others gods.\n",
      " possibility of contention is that idea of a god \"god,\" in the texts. which it word is not more the, the Jbl, a book ofutting the claims. In argued out that the the case book of different were including those ones, were associated as \" to the others. In also points that the term \" god \" in the Egyptian literature is not reference term for a deity was texts is to identifyre.\n",
      " the term of or, and namesography of the deity are not changing, the were not the to a single number of deities. and to a unifiedwou\n",
      "Предсказание по текущему фрагменту:  the, the J,, a book inutting the claims. He found out that the the case year of of have including those ones, are not as having to the other. He also points that the \" \"great \" was the Bible of of not \" term for a deity was author is to believere.\n",
      " Horn study of and, and descriptionsography of these deity are not changing, the were not the to a single number of deities. and to a completewou\n",
      "Целевой текст: Hornung's arguments have greatly influenced other scholars of Egyptian religion, but some still believe that at times the gods were more unified than he allows. Jan Assmann maintains that the notion of a single deity developed slowly through the New Kingdom, beginning with a focus on Amun @-@ Ra as the all @-@ important sun god. In his view, Atenism was an extreme outgrowth of this trend. It equated the single deity with the sun and dismissed all other gods. Then, in the backlash agains\n",
      "\n",
      "Пример 154 (Снижение потерь: 7.2888):\n",
      "Предыстория: = = Adaptations = =\n",
      "Сжатый контекст: #\"$\"#!!\"!###\"!\n",
      "Текущий фрагмент: An English @-@ language film adaptation of the novel was made in 2005 , directed by Luis Llosa , Mario Vargas Llosa 's cousin . It stars Isabella Rossellini as Urania Cabral , Paul Freeman as her father Agustin , Stephanie Leonidas as Uranita and Tomas Milian as Rafael Leonidas Trujillo . It was filmed in both the Dominican Republic and in Spain . Reviewing the film for the trade paper Variety , critic Jonathan Holland called it \" less a feast than a somewhat rushed , but thoroughly enjoyable ,\n",
      "Предсказание по сжатому контексту: An English @-@ language film adaptation of the novel was made in 2005, directed by Luis Llosa, Mario Vargas Llosa's cousin. It stars Isabella Rossellini as Urania Cabral, Paul Freeman as her father Agustin, Stephanie Leonidas as Uranita and Tomas Milian as Rafael Leonidas Trujillo. It was filmed in both the Dominican Republic and in Spain. Reviewing the film for the trade paper Variety, critic Jonathan Holland called it \" less a feast than a somewhat rushed, but thoroughly enjoyable,\n",
      "Предсказание по сырому контексту: \n",
      " \"ive. { Adaptalyses translation = =- = is. a English by made by the. and by David Buore and and Pas Llosa ands son, The was theabella Rossellini as theus,ello, aine as the husband,nesin Cab and D as as heria, Davidzanoas her.idas.jillo. The was released in Mexico English United Republic and the the. Theed the film, the New publication,, the David H wrote it \"a than film for a feast disappointing adaptation but still entertaining adaptation and\n",
      "Предсказание по текущему фрагменту: \n",
      "-#$mail- is is of the novel by released by the. and by David Buore and and Pas Llosa,s son, The was aabella Rossellini as aus,ral, aine as the husband,nesin Cab and D as as heria, Davidzanoas her.idas.jillo. The was released in Mexico English United Republic and the the.\n",
      "ers the film, the New publication,, the David H wrote it \"a than film than a feast disappointing adaptation and still entertaining film and\n",
      "Целевой текст: The novel has also been adapted for the stage, by Jorge Alí Triana and his daughter Veronica Triana, directed by Jorge Triana : the play was put on ( in Spanish, but with simultaneous translation to English ) at Repertorio Español ( www.repertorio.org / chivo ) in New York in 2003 ; and the production moved to Lima in 2007. A feature of the novel's stage version is that the same actor plays both Agustin Cabral and Rafael Trujillo. For reviewer Bruce Weber, this makes the point \" that Truj\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Epoch 7, Avg Compressed Context Loss: 11.3107, Avg Compression Ratio: 0.0000, Avg Divergence: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "Raw Context Loss",
         "type": "scatter",
         "uid": "408d0e58-61a6-4aab-94f6-55bac9469eec",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7
         ],
         "y": [
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Compressed Context Loss",
         "type": "scatter",
         "uid": "51abc40e-73e0-4555-900f-e694e1d56ed0",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7
         ],
         "y": [
          12.45771453102228,
          11.589769820876533,
          11.72688073918299,
          10.892910257813893,
          11.151580595122981,
          11.143476815393129,
          11.310671789391996
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Fragment Only Loss",
         "type": "scatter",
         "uid": "e634a77d-ce54-4ceb-b8f3-39c7d9ba14be",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7
         ],
         "y": [
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Графики потерь во время обучения"
        },
        "xaxis": {
         "title": {
          "text": "Эпоха"
         }
        },
        "yaxis": {
         "title": {
          "text": "Среднее значение потерь"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Примеры с максимальным снижением потерь после эпохи 7 ===\n",
      "\n",
      "Пример 86 (Снижение потерь: 17.3489):\n",
      "Предыстория: Predynastic Egypt originally consisted of small , independent villages . Because many deities in later times were strongly tied to particular towns and regions , many scholars have suggested that the pantheon formed as disparate communities coalesced into larger states , spreading and intermingling the worship of the old local deities . But others have argued that the most important predynastic gods were , like other elements of Egyptian culture , present all across the country despite the polit\n",
      "Сжатый контекст: #!!#!$!\"#\"\"!#\"%\"\n",
      "Текущий фрагмент: The final step in the formation of Egyptian religion was the unification of Egypt , in which rulers from Upper Egypt made themselves pharaohs of the entire country . These sacred kings and their subordinates assumed the exclusive right to interact with the gods , and kingship became the unifying focus of the religion .\n",
      "Предсказание по сжатому контексту: The final step in the formation of Egyptian religion was the unification of Egypt, in which rulers from Upper Egypt made themselves pharaohs of the entire country. These sacred kings and their subordinates assumed the exclusive right to interact with the gods, and kingship became the unifying focus of the religion. including\n",
      "Предсказание по сырому контексту: .chity, came of a, large kingdoms, The of of were Egypt Egyptian were associated associated to the deities, villages, the of have argued that the Egyptianheon of from a groups ofced into a groups. such out eventuallymingling. various of the gods gods deities. The the have suggested that the pant important deitiesynastic deities were the and the gods of the mythology, and in over the world. the facticooph form in the pant of the pant was the establishment of the's which which the and all Egypt and their knownaraohs and the city country. The ph deities were queens successors were the role power to rule with the people of and to and was a normifying principle of the religion. The\n",
      "Предсказание по текущему фрагменту: \n",
      " two is the process of the football is the establishment of the's which which the of all Egypt and their thearaohs. the people land. The ph places were queens successors were the title right to rule with the people and and to and was the supremeifying principle of the Egyptian.\n",
      "\n",
      "Целевой текст: New gods continued to emerge after this transformation. Some important deities like Isis and Amun are not known to have appeared until the Old Kingdom ( c. 2686 – 2181 BC ). Places and concepts could suddenly inspire the creation of a deity to represent them, and deities were sometimes created to serve as opposite @-@ sex counterparts to established gods or goddesses. Kings were said to be divine, although only a few continued to be worshipped long after their deaths. Some non @-@ royal h\n",
      "\n",
      "Пример 90 (Снижение потерь: 14.9662):\n",
      "Предыстория: = = = Locations = = =\n",
      "Сжатый контекст: #!!#!!$!!#\"\"!!#\"%#\n",
      "Текущий фрагмент: Gods were linked with specific regions of the universe . In Egyptian tradition , the world includes the earth , the sky , and the Duat . Surrounding them is the dark formlessness that existed before creation . The gods in general were said to dwell in the sky , although gods whose roles were linked with other parts of the universe were said to live in those places instead . Most events of mythology , set in a time before the gods ' withdrawal from the human realm , take place in an earthly setti\n",
      "Предсказание по сжатому контексту: Gods were linked with specific regions of the universe. In Egyptian tradition, the world includes the earth, the sky, and the Duat. Surrounding them is the dark formlessness that existed before creation. The gods in general were said to dwell in the sky, although gods whose roles were linked with other parts of the universe were said to live in those places instead. Most events of mythology, set in a time before the gods'withdrawal from the human realm, take place in an earthly setti\n",
      "Предсказание по сырому контексту: \n",
      " \" =. = = = = not to the locations of the world.\n",
      " other mythology, the gods was the gods, the moon, and the moonat, Therounding the are a world and of of is in the. The world were Egypt are connected to have in the earth and and they in presence were to to the realms of the universe were not to dwell in the regions.. The of in the are however in the world when the beginning,s from the world world, were place in the area worldler-\n",
      "Предсказание по текущему фрагменту: . of not to the genes of the brain,\n",
      " the mythology, the god was the heavens, the moon, and the moonat, Therounding the are a earth, of of is in the. The dark were the are not to have in the dark and and they in presence were to to the realms of the universe were not to dwell in the regions..\n",
      " of in the are however in the world when the creation,s from the world world, were place in the area worldler-\n",
      "Целевой текст: In the time after myth, most gods were said to be either in the sky or invisibly present within the world. Temples were their main means of contact with humanity. Each day, it was believed, the gods moved from the divine realm to their temples, their homes in the human world. There they inhabited the cult images, the statues that depicted deities and allowed humans to interact with them in temple rituals. This movement between realms was sometimes described as a journey between the sky\n",
      "\n",
      "Пример 193 (Снижение потерь: 8.0089):\n",
      "Предыстория: = = = Ziltoid the Omniscient and hiatus ( 2006 – 2008 ) = = =\n",
      "Сжатый контекст: !\"&!#\"$\"!\"\"!$$!$\n",
      "Текущий фрагмент: Townsend withdrew from touring to spend time with his family . From home , Townsend completed his second solo ambient album , The Hummer , releasing it exclusively on his website in November 2006 .\n",
      "Предсказание по сжатому контексту: Townsend withdrew from touring to spend time with his family. From home, Townsend completed his second solo ambient album, The Hummer, releasing it exclusively on his website in November 2006.\n",
      "Предсказание по сырому контексту: \n",
      " \" =EROch,. firstipcient, the thethe ) 2008 )\n",
      " = = = ( from the in pursue time with his family in = the he he was his PhD year album album, The Unming, in in in on his own. 2008 2008. The\n",
      "Предсказание по текущему фрагменту: ,, its the in focus time with his family.\n",
      " the, he was his career year album album, The Lastming, in in in on his own. October.. The\n",
      "Целевой текст: In May 2007, Townsend released Ziltoid the Omniscient, a tongue @-@ in @-@ cheek rock opera about the eponymous fictional alien. This was truly a solo album ; he programmed the drums using Drumkit from Hell, a software drum machine that uses samples recorded by Tomas Haake of Meshuggah and played all other instruments himself. Shortly after the album's release, Townsend announced that he no longer planned to tour or make albums with Strapping Young Lad or the Devin Townsend Band. He expl\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Epoch 8, Avg Compressed Context Loss: 10.7569, Avg Compression Ratio: 0.0000, Avg Divergence: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "Raw Context Loss",
         "type": "scatter",
         "uid": "408d0e58-61a6-4aab-94f6-55bac9469eec",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8
         ],
         "y": [
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Compressed Context Loss",
         "type": "scatter",
         "uid": "51abc40e-73e0-4555-900f-e694e1d56ed0",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8
         ],
         "y": [
          12.45771453102228,
          11.589769820876533,
          11.72688073918299,
          10.892910257813893,
          11.151580595122981,
          11.143476815393129,
          11.310671789391996,
          10.756902513165159
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Fragment Only Loss",
         "type": "scatter",
         "uid": "e634a77d-ce54-4ceb-b8f3-39c7d9ba14be",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8
         ],
         "y": [
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Графики потерь во время обучения"
        },
        "xaxis": {
         "title": {
          "text": "Эпоха"
         }
        },
        "yaxis": {
         "title": {
          "text": "Среднее значение потерь"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Примеры с максимальным снижением потерь после эпохи 8 ===\n",
      "\n",
      "Пример 184 (Снижение потерь: 16.5787):\n",
      "Предыстория: = = Other notable caves = =\n",
      "Сжатый контекст: !!$!\"!\"!!!\"!!!\n",
      "Текущий фрагмент: To the south @-@ east of the Great Cave is the second excavation , which faces east @-@ northeast . It includes a chapel at the north end . The front of this cave is completely destroyed ; only fragments of some semi @-@ columns remain . The interior has suffered water damage . The portico is 26 m ( 85 ft ) long and 11 m ( 36 ft ) deep . The chapel is supported by eight eight @-@ cornered columns and two demi @-@ columns and is irregular in shape . At the back of the portico are three chambers ;\n",
      "Предсказание по сжатому контексту: To the south @-@ east of the Great Cave is the second excavation, which faces east @-@ northeast. It includes a chapel at the north end. The front of this cave is completely destroyed ; only fragments of some semi @-@ columns remain. The interior has suffered water damage. The portico is 26 m ( 85 ft ) long and 11 m ( 36 ft ) deep. The chapel is supported by eight eight @-@ cornered columns and two demi @-@ columns and is irregular in shape. At the back of the portico are three chambers ;\n",
      "Предсказание по сырому контексту: \n",
      " \". features: = = be right of = = = = the cave Pyramid, a Great cave of which is the of-@ west of The is a large, the top end of The first entrance the chapel is a covered by the the of the of--met stone remain. The main of been a damage and The main of is a ft wide30 ft ) in and has m ( 15 ft ) wide. The main is located by a columns--@ columnsrug columns. a @arc--@ columns. a surroundedly shape. The the top of the chapelico is two @ with one\n",
      "Предсказание по текущему фрагменту:  the next,m1-, the bridge Lakes, a Great cave of which is the of-@ east of The is a large, the south end of The first of the chapel is a covered by the the of the of--circ semi remain. The north of been a damage and The main of is still feet wide50 ft ) in and has m ( 15 ft ) wide. The main is located by a columns--@ columnsrug columns. a @arc--@ columns. a supportedly shape. The the south of the chapelico is two @. one\n",
      "Целевой текст: A little to the south of the last cave is another cave in worse condition, with water damage. It is a portico in which each end probably had a chapel or room with pillars in front. Two of them have cells at the back. The central door at the back of the portico leads to a damaged shrine. The shrine door has door @-@ keepers at each side, leaning on dwarfs with flying figures over the head, with door @-@ keepers and demons on the jamb and architrave. The shrine is a plain room 6 m ( 20 ft\n",
      "\n",
      "Пример 91 (Снижение потерь: 14.6354):\n",
      "Предыстория: = = = Relationships = = =\n",
      "Сжатый контекст: !#!#!#!!!!\"!!!\"#\"\n",
      "Текущий фрагмент: Egyptian deities are connected in a complex and shifting array of relationships . A god 's connections and interactions with other deities helped define its character . Thus Isis , as the mother and protector of Horus , was a great healer as well as the patroness of kings . Such relationships were the base material from which myths were formed .\n",
      "Предсказание по сжатому контексту: Egyptian deities are connected in a complex and shifting array of relationships. A god's connections and interactions with other deities helped define its character. Thus Isis, as the mother and protector of Horus, was a great healer as well as the patroness of kings. Such relationships were the base material from which myths were formed..\n",
      "Предсказание по сырому контексту: \n",
      " \" =hips, = = = = = the to the way way complex way of relationships. The relationship iss relationship are relationships are other gods are to the relationship and The, was the a goddess of father of the, was a goddess goddess and well as a mother of of the and The a were also basis of for which the and constructed.\n",
      "\n",
      "Предсказание по текущему фрагменту: ,-, not to some way web complex way of ways. The number iss relationship to relationships with other gods are to the role and The, was the a goddess of father of the, was a goddess goddess and well as a mother of of the and The a were also basis of for which the and constructed.\n",
      "\n",
      "Целевой текст: Family relationships are a common type of connection between gods. Deities often form male and female pairs, reflecting the importance of procreation in Egyptian religious thought. Families of three deities, with a father, mother, and child, represent the creation of new life and the succession of the father by the child, a pattern that connects divine families with royal succession. Osiris, Isis, and Horus formed the quintessential family of this type. The pattern they set grew more\n",
      "\n",
      "Пример 33 (Снижение потерь: 12.0838):\n",
      "Предыстория: Child Thoughts in Picture and Verse ( by M. K. Westcott ) ; Blackie , 1925\n",
      "Сжатый контекст: \"#!\"$!\"!\"!$!!!$!\n",
      "Текущий фрагмент: Flower Fairies of the Autumn ; Blackie , 1926\n",
      "Предсказание по сжатому контексту: Flower Fairies of the Autumn ; Blackie, 1926\n",
      "Предсказание по сырому контексту: ,\n",
      " the Frames Video\n",
      "19 David.A. K ) )\n",
      "\n",
      " and, J ;ing, ( the World ( Blackie, 1925 Flower\n",
      "Предсказание по текущему фрагменту: .inging\n",
      " the World\n",
      " and and's by.\n",
      "Целевой текст: Summer Songs with Music ; Blackie, 1926\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Epoch 9, Avg Compressed Context Loss: 10.8437, Avg Compression Ratio: 0.0000, Avg Divergence: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "Raw Context Loss",
         "type": "scatter",
         "uid": "408d0e58-61a6-4aab-94f6-55bac9469eec",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Compressed Context Loss",
         "type": "scatter",
         "uid": "51abc40e-73e0-4555-900f-e694e1d56ed0",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          12.45771453102228,
          11.589769820876533,
          11.72688073918299,
          10.892910257813893,
          11.151580595122981,
          11.143476815393129,
          11.310671789391996,
          10.756902513165159,
          10.843724696164204
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Fragment Only Loss",
         "type": "scatter",
         "uid": "e634a77d-ce54-4ceb-b8f3-39c7d9ba14be",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
         ],
         "y": [
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Графики потерь во время обучения"
        },
        "xaxis": {
         "title": {
          "text": "Эпоха"
         }
        },
        "yaxis": {
         "title": {
          "text": "Среднее значение потерь"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Примеры с максимальным снижением потерь после эпохи 9 ===\n",
      "\n",
      "Пример 2 (Снижение потерь: 41.5035):\n",
      "Предыстория: = = Reception = =\n",
      "Сжатый контекст: !\"##!\"!\"\"!!!\n",
      "Текущий фрагмент: On its day of release in Japan , Valkyria Chronicles III topped both platform @-@ exclusive and multi @-@ platform sales charts . By early February , the game sold 102 @,@ 779 units , coming in second overall to The Last Story for the Wii . By the end of the year , the game had sold just over 152 @,@ 500 units .\n",
      "Предсказание по сжатому контексту: On its day of release in Japan, Valkyria Chronicles III topped both platform @-@ exclusive and multi @-@ platform sales charts. By early February, the game sold 102 @,@ 779 units, coming in second overall to The Last Story for the Wii. By the end of the year, the game had sold just over 152 @,@ 500 units.\n",
      "Предсказание по сырому контексту: \n",
      " \"gex. 0 0 = own = the = the. it =ries Chronicles 2: the charts and 1 and and to @--@ exclusive...\n",
      " comparison September, V game had over,- and and.,, and in at place behind the Legend of. the month U\n",
      " the end of the month, the game sold sold over over 1,,@ 7 units.\n",
      "\n",
      "Предсказание по текущему фрагменту:  the website, action, May, theiacria Chronicles 2: the the and and and and to @--platform exclusive...\n",
      " comparison October, V game had over,- and and.,, and in at place behind the Legend of. the month U\n",
      " the end of the month, V game sold sold over over 1,,@ 7 units.\n",
      "\n",
      "Целевой текст: Famitsu enjoyed the story, and were particularly pleased with the improvements to gameplay. Japanese gaming site Game Watch Impress, despite negatively noting its pacing and elements recycled from previous games, was generally positive about its story and characters, and found its gameplay entertaining despite off @-@ putting difficulty spikes. 4Gamer.net writer Naohiko Misuosame, in a \" Play Test \" article based on the game's PSN demo, felt that Valkyria Chronicles III provided a \" pro\n",
      "\n",
      "Пример 4 (Снижение потерь: 8.2791):\n",
      "Предыстория: Famitsu enjoyed the story , and were particularly pleased with the improvements to gameplay . Japanese gaming site Game Watch Impress , despite negatively noting its pacing and elements recycled from previous games , was generally positive about its story and characters , and found its gameplay entertaining despite off @-@ putting difficulty spikes . 4Gamer.net writer Naohiko Misuosame , in a \" Play Test \" article based on the game 's PSN demo , felt that Valkyria Chronicles III provided a \" pro\n",
      "Сжатый контекст: !\"#!#!\"!\"\"!!!\n",
      "Текущий фрагмент: PlayStation Official Magazine - UK praised the story 's blurring of Gallia 's moral standing , art style , and most points about its gameplay , positively noting the latter for both its continued quality and the tweaks to balance and content . Its one major criticism were multiple difficulty spikes , something that had affected the previous games . Heath Hindman of gaming website PlayStation Lifestyle praised the addition of non @-@ linear elements and improvements or removal of mechanics from V\n",
      "Предсказание по сжатому контексту: PlayStation Official Magazine - UK praised the story's blurring of Gallia's moral standing, art style, and most points about its gameplay, positively noting the latter for both its continued quality and the tweaks to balance and content. Its one major criticism were multiple difficulty spikes, something that had affected the previous games. Heath Hindman of gaming website PlayStation Lifestyle praised the addition of non @-@ linear elements and improvements or removal of mechanics from V September September\n",
      "Предсказание по сырому контексту: .ilies, a opportunity of but the very impressed with the story made the.\n",
      " fans culture KotFAQ haspressions which being reviewing the lack and pacing of from the games, has very pleased about the story and the. and was the story to. its- thetheing the on on\n",
      ". alsocom also andokiiko Kakiokaaki also who a reviewgoodthrough \" article, on the game, The story Vita,, said that thealkyria Chronicles 2 was a good fun- 4 \" \" \" \" the game ands storyurring of theows'ss lines compass and and style, and gameplay importantly of the story. and praising that story's its its story popularity and its fact made the. balance. 5 review of flaw was the instances spikes, and that was been the game games, 5cls, the site Game Magazineifestyle, the game of a--@ing gameplay, the to changes of the, previousalky\n",
      "Предсказание по текущему фрагменту: \n",
      "® Website\n",
      " The\n",
      " the game ofvery storyurring of theoway'ss lines compass and and director and and character importantly of the character. and. that ''s its its'success and its fact it the. balance.\n",
      " story of flaw was the instances settings and which that was been the game game in\n",
      "'ss, IGN magazine Games Magazineifestyle wrote the game of '- 'PC- gameplay to the to changes of the that theisc\n",
      "Целевой текст: In a preview of the TGS demo, Ryan Geddes of IGN was left excited as to where the game would go after completing the demo, along with enjoying the improved visuals over Valkyria Chronicles II. Kotaku's Richard Eisenbeis was highly positive about the game, citing is story as a return to form after Valkyria Chronicles II and its gameplay being the best in the series. His main criticisms were its length and gameplay repetition, along with expressing regret that it would not be localized.\n",
      "\n",
      "Пример 74 (Снижение потерь: 6.5009):\n",
      "Предыстория: = = = Cancer and comeback = = =\n",
      "Сжатый контекст: !\"!!\"!\"!#!$\n",
      "Текущий фрагмент: After two months of quietly dealing with his symptoms , Cullen 's wife finally called team trainers and asked them to check into his illness . The team took an x @-@ ray and found a large black shadow in his chest . He underwent a CAT scan which revealed Cullen had a baseball @-@ sized tumor ; he was diagnosed as having Non @-@ Hodgkin lymphoma . The diagnosis ended his season , and he immediately began chemotherapy treatments that quickly reduced his cancer . The tumor was gone by September 199\n",
      "Предсказание по сжатому контексту: After two months of quietly dealing with his symptoms, Cullen's wife finally called team trainers and asked them to check into his illness. The team took an x @-@ ray and found a large black shadow in his chest. He underwent a CAT scan which revealed Cullen had a baseball @-@ sized tumor ; he was diagnosed as having Non @-@ Hodgkin lymphoma. The diagnosis ended his season, and he immediately began chemotherapy treatments that quickly reduced his cancer. The tumor was gone by September 199\n",
      "Предсказание по сырому контексту: \n",
      " \" =, Reprodu. = = = cancer years of treatment waiting with the cancer, he wass health, gave him- to told if to help on his condition. They team members him MRI- x test- of a that tumor tumor tumor on Cullen left. The was a CT scan and revealed a's a tumor bat-@ tumor tumor. the was diagnosed with having a--C Cancerkin'soma. Cullen team was up life with but Cullen was went chemotherapy.. included progressed his symptoms risk Cullen team was removed within the of.\n",
      "Предсказание по текущему фрагменту:  the years, negotiations working with the own, he finallys wife, gave him- to told if to help on his condition.\n",
      " team was him MRI-Cray- and a that new amount tumor on his head. The was surgery CT scan and revealed a's a large bat-@ and tumor. he was diagnosed with having a--H Cancerkin'soma. The team was up life and but Cullen was went to.. included progressed his symptoms risk\n",
      " team was removed within the of.\n",
      "Целевой текст: On one day during his treatments, as his wife was wheeling him down a hospital corridor, Cullen went into cardiac arrest, requiring doctors to use a defibrillator to revive him. He underwent a bone marrow transplant that briefly reduced his immune system to the point that he could have very little human contact. Another examination in April 1998 revealed that the cancer was finally gone, and Cullen immediately began training for a comeback.\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Tokenizer padding token: [PAD]\n",
      "Epoch 10, Avg Compressed Context Loss: 10.8806, Avg Compression Ratio: 0.0000, Avg Divergence: 0.0000\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines+markers",
         "name": "Raw Context Loss",
         "type": "scatter",
         "uid": "408d0e58-61a6-4aab-94f6-55bac9469eec",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813,
          0.2385900616645813
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Compressed Context Loss",
         "type": "scatter",
         "uid": "51abc40e-73e0-4555-900f-e694e1d56ed0",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          12.45771453102228,
          11.589769820876533,
          11.72688073918299,
          10.892910257813893,
          11.151580595122981,
          11.143476815393129,
          11.310671789391996,
          10.756902513165159,
          10.843724696164204,
          10.880608045510229
         ]
        },
        {
         "mode": "lines+markers",
         "name": "Fragment Only Loss",
         "type": "scatter",
         "uid": "e634a77d-ce54-4ceb-b8f3-39c7d9ba14be",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303,
          0.27232280373573303
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Графики потерь во время обучения"
        },
        "xaxis": {
         "title": {
          "text": "Эпоха"
         }
        },
        "yaxis": {
         "title": {
          "text": "Среднее значение потерь"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Примеры с максимальным снижением потерь после эпохи 10 ===\n",
      "\n",
      "Пример 121 (Снижение потерь: 14.5311):\n",
      "Предыстория: In January 1844 , North Carolina Representative James Iver McKay , the chairman of the Committee on Ways and Means , solicited the views of Director Patterson on the gold dollar . Patterson had more of Gobrecht 's pattern dollar struck to show to committee members , again advising against a coin that if issued would be only about a half inch ( 13 mm ) in diameter . He told Treasury Secretary John C. Spencer that the only gold coins of that size in commerce , the Spanish and Colombian half @-@ es\n",
      "Сжатый контекст: ##!#\"!!\"!\"!!\"\"\"\n",
      "Текущий фрагмент: Even before 1848 , record amounts of gold were flowing to American mints to be struck into coin , but the California Gold Rush vastly increased these quantities . This renewed calls for a gold dollar , as well as for a higher denomination than the eagle ( $ 10 piece ) , then the largest gold coin . In January 1849 , McKay introduced a bill for a gold dollar , which was referred to his committee . There was much discussion in the press about the proposed coin ; one newspaper published a proposal\n",
      "Предсказание по сжатому контексту: Even before 1848, record amounts of gold were flowing to American mints to be struck into coin, but the California Gold Rush vastly increased these quantities. This renewed calls for a gold dollar, as well as for a higher denomination than the eagle ( $ 10 piece ), then the largest gold coin. In January 1849, McKay introduced a bill for a gold dollar, which was referred to his committee. There was much discussion in the press about the proposed coin ; one newspaper published a proposal\n",
      "Предсказание по сырому контексту:  the,,, the Carolina Governor John H.,, a first of the House on the and Means, introducedited the support of the of and the subject standard. The was been than alins's'ss views of than in be that the members that but, them the goldage would struck in be a a $ quarter- long1. ) long diameter. Patterson also committee Secretary William F. Cal that the gold way dollar that the size would circulation were the gold and American,,,dollar-, though the44, theers of gold were being into the merchantss and be used in theage and the gold dollar Company was out the numbers. The was demand for a new dollar, and well as a a gold denomination of the Spanish.the1. ).. were the dollar denomination coin in The 18 1845, the sent a bill to a new dollar, which he approved to as committee by The was no debate about the House about the gold bill, the of reported a story to\n",
      "Предсказание по текущему фрагменту:  the the months, the- of gold were found into the citiess. finance used in theage and the gold mint Rush was increased the amounts.\n",
      " was demand for a new standard, and well as a a gold standard of the dollar.the1 ) ). and which the dollar denomination dollar ever\n",
      " 18 1849, the's the new of a new dollar, which was then to as \" as The was a debate about the Congress about the bill bill, the of, a story to\n",
      "Целевой текст: McKay got his fellow Democrat, New Hampshire Senator Charles Atherton, to introduce the bill to authorize the gold dollar and the double eagle in the Senate on February 1, 1849 — Atherton was chairman of the Senate Finance Committee. McKay introduced a version into the House on February 20 ; debate began the same day. The dollar was attacked by congressmen from the Whig Party, then in the minority, on the grounds that it would be too small, would be counterfeited and in bad light might b\n",
      "\n",
      "Пример 44 (Снижение потерь: 8.1611):\n",
      "Предыстория: Simon the Swan ; Blackie , 1988\n",
      "Сжатый контекст: !\"\"!!\"#!!!\"\"$\n",
      "Текущий фрагмент: Flower Fairies of the Seasons ; Bedrick / Blackie , 1988\n",
      "Предсказание по сжатому контексту: Flower Fairies of the Seasons ; Bedrick / Blackie, 1988\n",
      "Предсказание по сырому контексту: , Great, and Swan the The ;ingies, the World, Blacke, Blackie, 1993 Flower\n",
      "Предсказание по текущему фрагменту: .inging\n",
      " the World\n",
      " androom's Thewood's The ;\n",
      "Целевой текст: A Little Book of Prayers and Hymns ; Frederick Warne, 1994\n",
      "\n",
      "Пример 120 (Снижение потерь: 7.7473):\n",
      "Предыстория: = = Inception = =\n",
      "Сжатый контекст: !##!#\"!!\"!\"!!!\"\"!\n",
      "Текущий фрагмент: In January 1844 , North Carolina Representative James Iver McKay , the chairman of the Committee on Ways and Means , solicited the views of Director Patterson on the gold dollar . Patterson had more of Gobrecht 's pattern dollar struck to show to committee members , again advising against a coin that if issued would be only about a half inch ( 13 mm ) in diameter . He told Treasury Secretary John C. Spencer that the only gold coins of that size in commerce , the Spanish and Colombian half @-@ es\n",
      "Предсказание по сжатому контексту: In January 1844, North Carolina Representative James Iver McKay, the chairman of the Committee on Ways and Means, solicited the views of Director Patterson on the gold dollar. Patterson had more of Gobrecht's pattern dollar struck to show to committee members, again advising against a coin that if issued would be only about a half inch ( 13 mm ) in diameter. He told Treasury Secretary John C. Spencer that the only gold coins of that size in commerce, the Spanish and Colombian half @-@ es\n",
      "Предсказание по сырому контексту: \n",
      " \"ject. False Falseception,,, the Carolina,, E.,, a first of the House on the and Means, saidited the advice of the of and the subject standard. The was been than alins's'ss views of than in be that the members that but, them the gold that would struck in be a used $ quarter of long1. ) long diameter. The also committee Secretary William F. Cal that the gold way dollar that the size would circulation were the gold and American,,, cents-,\n",
      "Предсказание по текущему фрагменту:  the,,, the Carolina Governor John H.,, a first of the House on the and Means, introducedited the support of the of and the subject standard. The was been than alins's'ss views of than in be that the members that but, them the goldage would struck in be a a $ quarter- long1. ) long diameter. Patterson also committee Secretary William F. Cal that the gold way dollar that the size would circulation were the gold and American,,,dollar-,\n",
      "Целевой текст: Even before 1848, record amounts of gold were flowing to American mints to be struck into coin, but the California Gold Rush vastly increased these quantities. This renewed calls for a gold dollar, as well as for a higher denomination than the eagle ( $ 10 piece ), then the largest gold coin. In January 1849, McKay introduced a bill for a gold dollar, which was referred to his committee. There was much discussion in the press about the proposed coin ; one newspaper published a proposal\n",
      "Model saved to context_optimizer2.pth\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from datasets import load_dataset\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Настройки устройства\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Загрузка модели GPT-2 и токенизатора\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "if not isinstance(tokenizer, GPT2Tokenizer):\n",
    "    raise ValueError(\"The tokenizer must be an instance of GPT2Tokenizer.\")\n",
    "\n",
    "# Проверка и установка pad_token для корректной работы с padding\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # Устанавливаем pad_token как eos_token\n",
    "    tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "    gpt2_model.resize_token_embeddings(len(tokenizer))  # Изменяем размер словаря модели после добавления токенов\n",
    "\n",
    "# Загрузка датасета и подготовка промежуточных данных\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"train\")\n",
    "intermediate_dataset_path = \"intermediate_dataset.json\"\n",
    "\n",
    "# Генерация промежуточного датасета, если он еще не создан\n",
    "if not os.path.exists(intermediate_dataset_path):\n",
    "    generate_intermediate_dataset(dataset, tokenizer, gpt2_model, device=device, intermediate_dataset_path=intermediate_dataset_path)\n",
    "else:\n",
    "    # Загрузка промежуточного датасета\n",
    "    intermediate_data = load_intermediate_dataset(intermediate_dataset_path)\n",
    "\n",
    "# Инициализация модели сжатия контекста\n",
    "input_size = 768  # Размер входных данных модели GPT-2\n",
    "hidden_size = 256  # Скрытый размер для оптимизатора контекста\n",
    "output_size = 30\n",
    "context_optimizer = ContextOptimizer(input_size, hidden_size, output_size).to(device)\n",
    "\n",
    "# Загрузка сохраненной модели, если она существует\n",
    "load_model(context_optimizer, context_optimizer, \"context_optimizer3.pth\")\n",
    "\n",
    "# Запуск обучения\n",
    "raw_loss_values, compressed_loss_values, fragment_loss_values = train_context_optimizer(context_optimizer, intermediate_data, tokenizer, gpt2_model, epochs=10, device=device)\n",
    "\n",
    "# Сохранение модели после обучения\n",
    "save_model(context_optimizer, context_optimizer, \"context_optimizer3.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предподготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Начало подготовки данных...\n",
      "Оценка времени выполнения цикла: 435.63 секунд для 999 записей.\n",
      "Промежуточный датасет создан с 197 записями, включая значения потерь и предсказания.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import time\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from datasets import load_dataset\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def generate_intermediate_dataset(dataset, tokenizer, gpt2_model, device=\"cpu\", intermediate_dataset_path=\"intermediate_dataset.json\"):\n",
    "    intermediate_data = []\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Подготавливаем данные\n",
    "    print(\"Начало подготовки данных...\")\n",
    "    prepared_data = prepare_data(dataset, max_length=500)\n",
    "\n",
    "    # Оценка времени выполнения цикла для первых пяти итераций\n",
    "    cycle_times = []\n",
    "    for i, (context, current_fragment, target) in enumerate(prepared_data[:5]):\n",
    "        if context is None or current_fragment is None:\n",
    "            continue\n",
    "\n",
    "        cycle_start_time = time.time()\n",
    "\n",
    "        # Подготовка целевого предсказания\n",
    "        target_input = tokenizer(target, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            target_output = gpt2_model(**target_input, output_hidden_states=True)\n",
    "            target_embedding = target_output.hidden_states[-1].mean(dim=1)\n",
    "\n",
    "        # Предсказание по сырому контексту (предыстория + текущий фрагмент)\n",
    "        raw_inputs = tokenizer(context + \" \" + current_fragment, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            raw_outputs = gpt2_model(**raw_inputs, output_hidden_states=True)\n",
    "            raw_combined_embedding = raw_outputs.hidden_states[-1].mean(dim=1)\n",
    "            raw_loss = criterion(raw_combined_embedding, target_embedding).item()\n",
    "            raw_prediction = tokenizer.decode(raw_outputs.logits.argmax(-1).squeeze().tolist())\n",
    "\n",
    "        # Предсказание только по текущему фрагменту\n",
    "        fragment_input = tokenizer(current_fragment, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            fragment_output = gpt2_model(**fragment_input, output_hidden_states=True)\n",
    "            fragment_embedding = fragment_output.hidden_states[-1].mean(dim=1)\n",
    "            fragment_loss = criterion(fragment_embedding, target_embedding).item()\n",
    "            fragment_prediction = tokenizer.decode(fragment_output.logits.argmax(-1).squeeze().tolist())\n",
    "\n",
    "        cycle_end_time = time.time()\n",
    "        cycle_times.append(cycle_end_time - cycle_start_time)\n",
    "\n",
    "        # Фильтрация по критерию fragment_loss > raw_loss\n",
    "        if fragment_loss > raw_loss and fragment_loss < 1:\n",
    "            # Сохранение всех значений и предсказаний\n",
    "            intermediate_data.append(\n",
    "                {\n",
    "                    \"context\": context,\n",
    "                    \"current_fragment\": current_fragment,\n",
    "                    \"target\": tokenizer.decode(target_input[\"input_ids\"].squeeze().tolist()),\n",
    "                    \"raw_loss\": raw_loss,\n",
    "                    \"fragment_loss\": fragment_loss,\n",
    "                    \"raw_prediction\": raw_prediction,\n",
    "                    \"fragment_prediction\": fragment_prediction,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # Оценка общего времени выполнения цикла на основе первых пяти измерений\n",
    "    avg_cycle_time = sum(cycle_times) / len(cycle_times) if cycle_times else 0\n",
    "    estimated_total_time = avg_cycle_time * len(prepared_data)\n",
    "    print(f\"Оценка времени выполнения цикла: {estimated_total_time:.2f} секунд для {len(prepared_data)} записей.\")\n",
    "\n",
    "    # Продолжение обработки остальных данных после оценки времени\n",
    "    for i, (context, current_fragment, target) in enumerate(prepared_data[5:]):\n",
    "        if context is None or current_fragment is None:\n",
    "            continue\n",
    "\n",
    "        # Подготовка целевого предсказания\n",
    "        target_input = tokenizer(target, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            target_output = gpt2_model(**target_input, output_hidden_states=True)\n",
    "            target_embedding = target_output.hidden_states[-1].mean(dim=1)\n",
    "\n",
    "        # Предсказание по сырому контексту (предыстория + текущий фрагмент)\n",
    "        raw_inputs = tokenizer(context + \" \" + current_fragment, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            raw_outputs = gpt2_model(**raw_inputs, output_hidden_states=True)\n",
    "            raw_combined_embedding = raw_outputs.hidden_states[-1].mean(dim=1)\n",
    "            raw_loss = criterion(raw_combined_embedding, target_embedding).item()\n",
    "            raw_prediction = tokenizer.decode(raw_outputs.logits.argmax(-1).squeeze().tolist())\n",
    "\n",
    "        # Предсказание только по текущему фрагменту\n",
    "        fragment_input = tokenizer(current_fragment, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            fragment_output = gpt2_model(**fragment_input, output_hidden_states=True)\n",
    "            fragment_embedding = fragment_output.hidden_states[-1].mean(dim=1)\n",
    "            fragment_loss = criterion(fragment_embedding, target_embedding).item()\n",
    "            fragment_prediction = tokenizer.decode(fragment_output.logits.argmax(-1).squeeze().tolist())\n",
    "\n",
    "        # Фильтрация по критерию fragment_loss > raw_loss and fragment_loss <= 1\n",
    "        if fragment_loss > raw_loss and fragment_loss < 1:\n",
    "            # Сохранение всех значений и предсказаний\n",
    "            intermediate_data.append(\n",
    "                {\n",
    "                    \"context\": context,\n",
    "                    \"current_fragment\": current_fragment,\n",
    "                    \"target\": tokenizer.decode(target_input[\"input_ids\"].squeeze().tolist()),\n",
    "                    \"raw_loss\": raw_loss,\n",
    "                    \"fragment_loss\": fragment_loss,\n",
    "                    \"raw_prediction\": raw_prediction,\n",
    "                    \"fragment_prediction\": fragment_prediction,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # Сохранение промежуточного датасета в JSON\n",
    "    with open(intermediate_dataset_path, \"w\") as f:\n",
    "        json.dump(intermediate_data, f, indent=4)\n",
    "\n",
    "    print(f\"Промежуточный датасет создан с {len(intermediate_data)} записями, включая значения потерь и предсказания.\")\n",
    "\n",
    "\n",
    "# Настройки\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Загружаем датасет wikitext-2-raw-v1\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"train\")\n",
    "\n",
    "# Инициализация токенизатора и модели GPT-2\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "# Set the pad_token to eos_token if not already set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # Use eos_token as pad_token\n",
    "    tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "    gpt2_model.resize_token_embeddings(len(tokenizer))  # Update model embeddings after modifying the tokenizer\n",
    "\n",
    "# Задаем путь для сохранения промежуточного датасета\n",
    "intermediate_dataset_path = \"intermediate_dataset.json\"\n",
    "\n",
    "# Генерация промежуточного датасета\n",
    "generate_intermediate_dataset(dataset, tokenizer, gpt2_model, device, intermediate_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\MUIV\\concl\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начало подготовки данных...\n",
      "Данные подгружены.\n",
      "Оценка времени подготовки данных: 276.26 секунд для 999 записей.\n",
      "Промежуточный датасет создан с 999 записями, включая значения потерь.\n"
     ]
    }
   ],
   "source": [
    "# Устарело\n",
    "import json\n",
    "import torch\n",
    "import time\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from datasets import load_dataset\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def generate_intermediate_dataset(dataset, tokenizer, gpt2_model, device=\"cpu\", intermediate_dataset_path=\"intermediate_dataset.json\"):\n",
    "    intermediate_data = []\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Подготовка данных\n",
    "    print(\"Начало подготовки данных...\")\n",
    "    start_time = time.time()\n",
    "    prepared_data = prepare_data(dataset, max_length=500)\n",
    "    print(\"Данные подгружены.\")\n",
    "    # Оценка времени подготовки данных\n",
    "    preparation_times = []\n",
    "    for i, (context, current_fragment, target) in enumerate(prepared_data[:5]):\n",
    "        if context is None or current_fragment is None:\n",
    "            continue\n",
    "        preparation_times.append(time.time() - start_time)\n",
    "        start_time = time.time()\n",
    "\n",
    "    avg_preparation_time = sum(preparation_times) / len(preparation_times)\n",
    "    estimated_total_time = avg_preparation_time * len(prepared_data)\n",
    "    print(f\"Оценка времени подготовки данных: {estimated_total_time:.2f} секунд для {len(prepared_data)} записей.\")\n",
    "\n",
    "    for i, (context, current_fragment, target) in enumerate(prepared_data):\n",
    "        if context is None or current_fragment is None:\n",
    "            continue\n",
    "\n",
    "        # Подготовка целевого предсказания\n",
    "        target_input = tokenizer(target, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            target_output = gpt2_model(**target_input, output_hidden_states=True)\n",
    "            target_embedding = target_output.hidden_states[-1].mean(dim=1)\n",
    "\n",
    "        # Предсказание по сырому контексту (предыстория + текущий фрагмент)\n",
    "        raw_inputs = tokenizer(context + \" \" + current_fragment, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            raw_outputs = gpt2_model(**raw_inputs, output_hidden_states=True)\n",
    "            raw_combined_embedding = raw_outputs.hidden_states[-1].mean(dim=1)\n",
    "            raw_loss = criterion(raw_combined_embedding, target_embedding).item()\n",
    "\n",
    "        # Предсказание только по текущему фрагменту\n",
    "        fragment_input = tokenizer(current_fragment, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            fragment_output = gpt2_model(**fragment_input, output_hidden_states=True)\n",
    "            fragment_embedding = fragment_output.hidden_states[-1].mean(dim=1)\n",
    "            fragment_loss = criterion(fragment_embedding, target_embedding).item()\n",
    "\n",
    "        # Сохранение всех значений и предсказаний\n",
    "        intermediate_data.append(\n",
    "            {\n",
    "                \"context\": context,\n",
    "                \"current_fragment\": current_fragment,\n",
    "                \"target\": tokenizer.decode(target_input[\"input_ids\"].squeeze().tolist()),\n",
    "                \"raw_loss\": raw_loss,\n",
    "                \"fragment_loss\": fragment_loss,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Сохранение промежуточного датасета в JSON\n",
    "    with open(intermediate_dataset_path, \"w\") as f:\n",
    "        json.dump(intermediate_data, f, indent=4)\n",
    "\n",
    "    print(f\"Промежуточный датасет создан с {len(intermediate_data)} записями, включая значения потерь.\")\n",
    "\n",
    "\n",
    "# Настройки\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Загружаем датасет wikitext-2-raw-v1\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"train\")\n",
    "\n",
    "# Инициализация токенизатора и модели GPT-2\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)  # Используем 'cpu', можно заменить на 'cuda' при использовании GPU\n",
    "\n",
    "# Задаем путь для сохранения промежуточного датасета\n",
    "intermediate_dataset_path = \"intermediate_dataset.json\"\n",
    "\n",
    "# Генерация промежуточного датасета\n",
    "generate_intermediate_dataset(dataset, tokenizer, gpt2_model, device, intermediate_dataset_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
