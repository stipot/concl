{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модульная архитектура"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import time\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определение Моделей\n",
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, latent_dim=512):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            # Слои энкодера\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 16x16\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 8x8\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 4x4\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 2x2\n",
    "        )\n",
    "        self.fc_enc = nn.Linear(512 * 2 * 2, latent_dim)\n",
    "        self.fc_dec = nn.Linear(latent_dim, 512 * 2 * 2)\n",
    "        self.decoder = nn.Sequential(\n",
    "            # Слои декодера\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),  # 4x4\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),  # 8x8\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),  # 16x16\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),  # 32x32\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        z = z.view(z.size(0), -1)\n",
    "        z = self.fc_enc(z)\n",
    "\n",
    "        h = self.fc_dec(z)\n",
    "        h = h.view(z.size(0), 512, 2, 2)\n",
    "        x_recon = self.decoder(h)\n",
    "        return x_recon, z\n",
    "\n",
    "    def encode(self, x, require_grad=True):\n",
    "        if not require_grad:\n",
    "            with torch.no_grad():\n",
    "                z = self.encoder(x)\n",
    "                z = z.view(z.size(0), -1)\n",
    "                z = self.fc_enc(z)\n",
    "        else:\n",
    "            z = self.encoder(x)\n",
    "            z = z.view(z.size(0), -1)\n",
    "            z = self.fc_enc(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BinaryClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim=512):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "        self.fc = nn.Sequential(nn.Linear(embedding_dim, 256), nn.ReLU(), nn.Dropout(0.5), nn.Linear(256, 1))  # Выходной слой для бинарной классификации\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.fc(z)\n",
    "        return out  # Без сигмоида, так как используем BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. CombinedBinaryClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' class CombinedBinaryClassifier(nn.Module):\\n\\n    def __init__(self, binary_classifiers, num_classes):\\n\\n\\n        super(CombinedBinaryClassifier, self).__init__()\\n\\n        self.binary_classifiers = nn.ModuleList(binary_classifiers)\\n\\n        self.num_classes = num_classes\\n\\n\\n\\n    def forward(self, z):\\n\\n\\n        logits = []\\n\\n        for classifier in self.binary_classifiers:\\n\\n            out = classifier(z)\\n\\n\\n            logits.append(out)\\n\\n        logits = torch.cat(logits, dim=1)  # [batch, num_classes]\\n\\n\\n        return logits  # Без активации, будем применять sigmoid позже '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deprecated\n",
    "\"\"\" class CombinedBinaryClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, binary_classifiers, num_classes):\n",
    "\n",
    "\n",
    "\n",
    "        super(CombinedBinaryClassifier, self).__init__()\n",
    "\n",
    "        self.binary_classifiers = nn.ModuleList(binary_classifiers)\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "\n",
    "\n",
    "\n",
    "        logits = []\n",
    "\n",
    "        for classifier in self.binary_classifiers:\n",
    "\n",
    "            out = classifier(z)\n",
    "\n",
    "\n",
    "\n",
    "            logits.append(out)\n",
    "\n",
    "        logits = torch.cat(logits, dim=1)  # [batch, num_classes]\n",
    "\n",
    "\n",
    "\n",
    "        return logits  # Без активации, будем применять sigmoid позже \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Определение Класса Trainer\n",
    "Класс Trainer будет управлять процессами обучения автокодировщика, бинарных классификаторов, объединённой модели и дообучения энкодера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, num_classes=10, latent_dim=512, batch_size=128, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", save_dir=\"./saved_models\"):\n",
    "        self.num_classes = num_classes\n",
    "        self.latent_dim = latent_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.save_dir = save_dir\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "\n",
    "        # Инициализация моделей\n",
    "        self.autoencoder = Autoencoder(latent_dim=self.latent_dim).to(self.device)\n",
    "        self.binary_classifiers = nn.ModuleList([BinaryClassifier(embedding_dim=self.latent_dim).to(self.device) for _ in range(self.num_classes)])\n",
    "\n",
    "        # Потери и точности\n",
    "        self.ae_loss_log = []\n",
    "        self.classifier_loss_log = [[] for _ in range(self.num_classes)]  # Потери для каждого классификатора\n",
    "        self.classifier_acc_log = [[] for _ in range(self.num_classes)]  # Точности для каждого классификатора\n",
    "        self.fine_tune_loss_log = []\n",
    "        self.fine_tune_acc_log = []\n",
    "\n",
    "        # Точности до и после финетюнинга\n",
    "        self.acc_combined_before = 0.0\n",
    "        self.error_rate_before = 1.0\n",
    "        self.acc_combined_after = 0.0\n",
    "        self.error_rate_after = 1.0\n",
    "\n",
    "        # Хранение предсказаний и истинных меток для матрицы ошибок\n",
    "        self.pred_all_before = [[] for _ in range(self.num_classes)]\n",
    "        self.target_all_before = [[] for _ in range(self.num_classes)]\n",
    "        self.pred_all_after = [[] for _ in range(self.num_classes)]\n",
    "        self.target_all_after = [[] for _ in range(self.num_classes)]\n",
    "\n",
    "    def prepare_dataloaders(self, train_subset, test_subset):\n",
    "        self.train_loader = DataLoader(train_subset, batch_size=self.batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "        self.test_loader = DataLoader(test_subset, batch_size=self.batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    def train_autoencoder(self, epochs=10, lr=0.001):\n",
    "        print(\"\\nИнициализация и обучение автокодировщика...\")\n",
    "        optimizer_ae = optim.Adam(self.autoencoder.parameters(), lr=lr)\n",
    "        criterion_ae = nn.MSELoss()\n",
    "\n",
    "        for ep in range(epochs):\n",
    "            epoch_start = time.time()\n",
    "            self.autoencoder.train()\n",
    "            running_loss = 0.0\n",
    "            for d, _ in self.train_loader:\n",
    "                d = d.to(self.device)\n",
    "                optimizer_ae.zero_grad()\n",
    "                x_recon, z = self.autoencoder(d)\n",
    "                loss = criterion_ae(x_recon, d)\n",
    "                loss.backward()\n",
    "                optimizer_ae.step()\n",
    "                running_loss += loss.item() * d.size(0)\n",
    "            epoch_loss = running_loss / len(self.train_loader.dataset)\n",
    "            self.ae_loss_log.append(epoch_loss)\n",
    "            epoch_end = time.time()\n",
    "            print(f\"Эпоха {ep+1}/{epochs}, Потери AE: {epoch_loss:.6f}, Время: {epoch_end - epoch_start:.2f} сек.\")\n",
    "\n",
    "    def save_autoencoder(self, suffix=\"before_finetune\"):\n",
    "        autoenc_save_path = os.path.join(self.save_dir, f\"autoencoder_{suffix}.pth\")\n",
    "        torch.save(self.autoencoder.state_dict(), autoenc_save_path)\n",
    "        print(f\"Autoencoder сохранён по пути: {autoenc_save_path}\")\n",
    "\n",
    "    def save_classifier(self, cls, suffix=\"before_finetune\"):\n",
    "        classifier_save_path = os.path.join(self.save_dir, f\"classifier_class_{cls}_{suffix}.pth\")\n",
    "        torch.save(self.binary_classifiers[cls].state_dict(), classifier_save_path)\n",
    "        print(f\"BinaryClassifier для класса {cls} сохранён по пути: {classifier_save_path}\")\n",
    "\n",
    "    def load_autoencoder(self, suffix=\"before_finetune\"):\n",
    "        autoenc_save_path = os.path.join(self.save_dir, f\"autoencoder_{suffix}.pth\")\n",
    "        if os.path.exists(autoenc_save_path):\n",
    "            self.autoencoder.load_state_dict(torch.load(autoenc_save_path))\n",
    "            self.autoencoder.to(self.device)\n",
    "            print(f\"Autoencoder загружен из {autoenc_save_path}\")\n",
    "        else:\n",
    "            print(f\"Файл {autoenc_save_path} не найден.\")\n",
    "\n",
    "    def load_classifier(self, cls, suffix=\"before_finetune\"):\n",
    "        classifier_save_path = os.path.join(self.save_dir, f\"classifier_class_{cls}_{suffix}.pth\")\n",
    "        if os.path.exists(classifier_save_path):\n",
    "            self.binary_classifiers[cls].load_state_dict(torch.load(classifier_save_path))\n",
    "            self.binary_classifiers[cls].to(self.device)\n",
    "            print(f\"BinaryClassifier для класса {cls} загружен из {classifier_save_path}\")\n",
    "        else:\n",
    "            print(f\"Файл {classifier_save_path} не найден.\")\n",
    "\n",
    "    def train_binary_classifier(self, cls, epochs=10, lr=0.001):\n",
    "        print(f\"\\nОбучение бинарного классификатора для класса {cls}...\")\n",
    "        criterion_cls = nn.BCEWithLogitsLoss()\n",
    "        optimizer_cls = optim.Adam(self.binary_classifiers[cls].parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "        # Замораживаем автокодировщик\n",
    "        self.autoencoder.eval()\n",
    "        for param in self.autoencoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for ep in range(epochs):\n",
    "            epoch_start = time.time()\n",
    "            self.binary_classifiers[cls].train()\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for data, target in self.train_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                optimizer_cls.zero_grad()\n",
    "\n",
    "                z = self.autoencoder.encode(data, require_grad=False)\n",
    "                logits = self.binary_classifiers[cls](z).squeeze()\n",
    "                binary_targets = (target == cls).float()\n",
    "\n",
    "                loss = criterion_cls(logits, binary_targets)\n",
    "                loss.backward()\n",
    "                optimizer_cls.step()\n",
    "\n",
    "                running_loss += loss.item() * data.size(0)\n",
    "\n",
    "                preds = (torch.sigmoid(logits) >= 0.5).float()\n",
    "                correct += (preds == binary_targets).sum().item()\n",
    "                total += data.size(0)\n",
    "            epoch_loss = running_loss / total\n",
    "            epoch_acc = correct / total\n",
    "            self.classifier_loss_log[cls].append(epoch_loss)\n",
    "            self.classifier_acc_log[cls].append(epoch_acc)\n",
    "            epoch_end = time.time()\n",
    "            print(f\"Эпоха {ep+1}/{epochs}, Class {cls}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc*100:.2f}%, Время: {epoch_end - epoch_start:.2f} сек.\")\n",
    "\n",
    "        # Возвращаем автокодировщик в режим train, если необходимо\n",
    "        self.autoencoder.train()\n",
    "        for param in self.autoencoder.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def evaluate_combined_model(self, loader, before_finetune=True):\n",
    "        if before_finetune:\n",
    "            pred_all = self.pred_all_before\n",
    "            target_all = self.target_all_before\n",
    "        else:\n",
    "            pred_all = self.pred_all_after\n",
    "            target_all = self.target_all_after\n",
    "\n",
    "        for cls in range(self.num_classes):\n",
    "            pred_all[cls] = []\n",
    "            target_all[cls] = []\n",
    "\n",
    "        self.autoencoder.eval()\n",
    "        for cls in range(self.num_classes):\n",
    "            self.binary_classifiers[cls].eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                z = self.autoencoder.encode(data, require_grad=False)\n",
    "                for cls in range(self.num_classes):\n",
    "                    logits = self.binary_classifiers[cls](z).squeeze()\n",
    "                    preds = (torch.sigmoid(logits) >= 0.5).float()\n",
    "                    pred_all[cls].extend(preds.cpu().numpy())\n",
    "                    binary_targets = (target == cls).float()\n",
    "                    target_all[cls].extend(binary_targets.cpu().numpy())\n",
    "\n",
    "        # Расчёт общей точности и error rate\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        for cls in range(self.num_classes):\n",
    "            cls_correct = sum([1 for p, t in zip(pred_all[cls], target_all[cls]) if p == t])\n",
    "            total_correct += cls_correct\n",
    "            total_samples += len(target_all[cls])\n",
    "        accuracy = total_correct / total_samples\n",
    "        error_rate = 1 - accuracy\n",
    "\n",
    "        if before_finetune:\n",
    "            self.acc_combined_before = accuracy\n",
    "            self.error_rate_before = error_rate\n",
    "            print(f\"\\nCombined model accuracy before fine-tuning: {accuracy*100:.2f}%\")\n",
    "            print(f\"Error rate before fine-tuning: {error_rate*100:.2f}%\")\n",
    "        else:\n",
    "            self.acc_combined_after = accuracy\n",
    "            self.error_rate_after = error_rate\n",
    "            print(f\"\\nCombined model accuracy after fine-tuning: {accuracy*100:.2f}%\")\n",
    "            print(f\"Error rate after fine-tuning: {error_rate*100:.2f}%\")\n",
    "\n",
    "        return accuracy, error_rate, pred_all, target_all\n",
    "\n",
    "    def accuracy_per_class(self, pred_all, target_all, before_finetune=True):\n",
    "        print(\"\\nAccuracy per class:\")\n",
    "        for cls in range(self.num_classes):\n",
    "            correct = sum([1 for p, t in zip(pred_all[cls], target_all[cls]) if p == t])\n",
    "            total = len(target_all[cls])\n",
    "            acc = (correct / total * 100) if total > 0 else 0.0\n",
    "            print(f\"Class {cls}: {acc:.2f}%\")\n",
    "\n",
    "    def fine_tune_encoder(self, fine_tune_loader, epochs=3, lr=0.0005):\n",
    "        print(\"\\nДообучение энкодера на небольшой выборке с фиксированными классификаторами...\")\n",
    "        criterion_fine = nn.BCEWithLogitsLoss()\n",
    "        optimizer_enc = optim.Adam([p for p in self.autoencoder.parameters() if p.requires_grad], lr=lr, weight_decay=1e-5)\n",
    "\n",
    "        for ep in range(epochs):\n",
    "            ep_start = time.time()\n",
    "            self.autoencoder.train()\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for data, target in fine_tune_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device).long()\n",
    "                optimizer_enc.zero_grad()\n",
    "                z = self.autoencoder.encode(data, require_grad=True)  # Позволяем градиентам проходить\n",
    "                loss_total = 0.0\n",
    "                for cls in range(self.num_classes):\n",
    "                    logits = self.binary_classifiers[cls](z).squeeze()\n",
    "                    binary_targets = (target == cls).float()\n",
    "                    loss = criterion_fine(logits, binary_targets)\n",
    "                    loss_total += loss\n",
    "                loss_total.backward()\n",
    "                optimizer_enc.step()\n",
    "\n",
    "                running_loss += loss_total.item() * data.size(0)\n",
    "\n",
    "                # Для общей точности агрегируем предсказания\n",
    "                logits_all = torch.stack([torch.sigmoid(self.binary_classifiers[cls](z).squeeze()) for cls in range(self.num_classes)], dim=1)\n",
    "                preds_cls = torch.argmax(logits_all, dim=1)\n",
    "                correct += (preds_cls == target).sum().item()\n",
    "                total += target.size(0)\n",
    "            epoch_loss = running_loss / total\n",
    "            epoch_acc = correct / total\n",
    "            self.fine_tune_loss_log.append(epoch_loss)\n",
    "            self.fine_tune_acc_log.append(epoch_acc)\n",
    "            ep_end = time.time()\n",
    "            print(f\"Fine-tuning Epoch {ep+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc*100:.2f}%, Время: {ep_end - epoch_start:.2f} сек.\")\n",
    "\n",
    "    def plot_metrics(self, before_finetune=True, after_finetune=False):\n",
    "        if before_finetune:\n",
    "            # Графики потерь и точности бинарных классификаторов\n",
    "            fig = make_subplots(rows=2, cols=5, subplot_titles=[f\"Class {i} Loss\" for i in range(self.num_classes)] + [f\"Class {i} Accuracy\" for i in range(self.num_classes)])\n",
    "\n",
    "            for cls in range(self.num_classes):\n",
    "                # Определение позиции subplot\n",
    "                if cls < 5:\n",
    "                    row = 1\n",
    "                    col = cls + 1\n",
    "                else:\n",
    "                    row = 2\n",
    "                    col = cls - 5 + 1  # Классы 5-9 идут во второй строке, столбцы 1-5\n",
    "\n",
    "                # Потери\n",
    "                fig.add_trace(go.Scatter(y=self.classifier_loss_log[cls], mode=\"lines+markers\", name=f\"Class {cls} Loss\", showlegend=False), row=row, col=col)\n",
    "\n",
    "                # Точность\n",
    "                fig.add_trace(go.Scatter(y=self.classifier_acc_log[cls], mode=\"lines+markers\", name=f\"Class {cls} Accuracy\", showlegend=False), row=row, col=col)\n",
    "\n",
    "            fig.update_layout(height=800, width=2000, title_text=\"Binary Classifiers Loss and Accuracy Before Fine-tuning\", showlegend=False)\n",
    "            fig.show()\n",
    "\n",
    "        if after_finetune:\n",
    "            # Графики потерь и точности дообучения энкодера\n",
    "            fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Fine-tune Loss\", \"Fine-tune Accuracy\"))\n",
    "\n",
    "            # Потери дообучения\n",
    "            fig.add_trace(go.Scatter(y=self.fine_tune_loss_log, mode=\"lines+markers\", name=\"Fine-tune Loss\"), row=1, col=1)\n",
    "\n",
    "            # Точность дообучения\n",
    "            fig.add_trace(go.Scatter(y=self.fine_tune_acc_log, mode=\"lines+markers\", name=\"Fine-tune Accuracy\"), row=1, col=2)\n",
    "\n",
    "            fig.update_layout(height=600, width=1000, title_text=\"Fine-tuning Metrics\", showlegend=True)\n",
    "            fig.show()\n",
    "\n",
    "    def plot_confusion_matrix(self, before_finetune=True, after_finetune=True):\n",
    "        if before_finetune:\n",
    "            for cls in range(self.num_classes):\n",
    "                cm = confusion_matrix(self.target_all_before[cls], self.pred_all_before[cls], labels=[0, 1])\n",
    "                fig = go.Figure(data=go.Heatmap(z=cm, x=[\"Pred 0\", \"Pred 1\"], y=[\"True 0\", \"True 1\"], colorscale=\"Blues\", showscale=True))\n",
    "                fig.update_layout(title=f\"Confusion Matrix for Class {cls} Before Fine-tuning\", xaxis_title=\"Predicted Label\", yaxis_title=\"True Label\")\n",
    "                fig.show()\n",
    "\n",
    "        if after_finetune:\n",
    "            for cls in range(self.num_classes):\n",
    "                cm = confusion_matrix(self.target_all_after[cls], self.pred_all_after[cls], labels=[0, 1])\n",
    "                fig = go.Figure(data=go.Heatmap(z=cm, x=[\"Pred 0\", \"Pred 1\"], y=[\"True 0\", \"True 1\"], colorscale=\"Blues\", showscale=True))\n",
    "                fig.update_layout(title=f\"Confusion Matrix for Class {cls} After Fine-tuning\", xaxis_title=\"Predicted Label\", yaxis_title=\"True Label\")\n",
    "                fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Подготовка Данных\n",
    "Создадим утилитные функции для подготовки датасетов и загрузчиков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataset(dataset, num_classes, min_samples):\n",
    "    \"\"\"\n",
    "    Фильтрует датасет, оставляя только `num_classes` классов и минимум `min_samples` образцов на класс.\n",
    "    \"\"\"\n",
    "    class_counts = Counter()\n",
    "    class_indices = defaultdict(list)\n",
    "\n",
    "    # Собираем индексы для каждого класса\n",
    "    for idx, (_, target) in enumerate(dataset):\n",
    "        if target < num_classes:\n",
    "            class_indices[target].append(idx)\n",
    "            class_counts[target] += 1\n",
    "\n",
    "    # Проверяем, что каждый класс имеет минимум образцов\n",
    "    for cls in range(num_classes):\n",
    "        if class_counts[cls] < min_samples:\n",
    "            raise ValueError(f\"Класс {cls} имеет только {class_counts[cls]} образцов, требуется минимум {min_samples}.\")\n",
    "\n",
    "    # Ограничиваем количество образцов до min_samples для каждого класса\n",
    "    selected_indices = []\n",
    "    for cls in range(num_classes):\n",
    "        selected_indices.extend(class_indices[cls][:min_samples])\n",
    "\n",
    "    return Subset(dataset, selected_indices)\n",
    "\n",
    "\n",
    "def create_fine_tuning_subset(dataset, num_classes, samples_per_class=200):\n",
    "    \"\"\"\n",
    "    Создаёт выборку для дообучения энкодера с фиксированным количеством образцов на класс.\n",
    "    \"\"\"\n",
    "    selected_indices = []\n",
    "    class_counts = Counter()\n",
    "    class_indices = defaultdict(list)\n",
    "\n",
    "    for idx, (_, target) in enumerate(dataset):\n",
    "        if target < num_classes and class_counts[target] < samples_per_class:\n",
    "            class_indices[target].append(idx)\n",
    "            class_counts[target] += 1\n",
    "            selected_indices.append(idx)\n",
    "        if all(count >= samples_per_class for count in class_counts.values()):\n",
    "            break\n",
    "\n",
    "    return Subset(dataset, selected_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Основной Скрипт\n",
    "Теперь объединим всё вместе в основном скрипте, который будет использовать класс Trainer для выполнения всех этапов обучения, сохранения и загрузки моделей.\n",
    "\n",
    "### 4.1. Ячейка 1: Обучение Автокодировщика и Бинарных Классификаторов, Сохранение Моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Инициализация и обучение автокодировщика...\n",
      "Эпоха 1/10, Потери AE: 1.551726, Время: 15.88 сек.\n",
      "Эпоха 2/10, Потери AE: 1.291110, Время: 13.65 сек.\n",
      "Эпоха 3/10, Потери AE: 1.212238, Время: 13.63 сек.\n",
      "Эпоха 4/10, Потери AE: 1.188395, Время: 13.55 сек.\n",
      "Эпоха 5/10, Потери AE: 1.181721, Время: 13.54 сек.\n",
      "Эпоха 6/10, Потери AE: 1.160455, Время: 13.48 сек.\n",
      "Эпоха 7/10, Потери AE: 1.139231, Время: 13.45 сек.\n",
      "Эпоха 8/10, Потери AE: 1.135714, Время: 13.50 сек.\n",
      "Эпоха 9/10, Потери AE: 1.124379, Время: 13.42 сек.\n",
      "Эпоха 10/10, Потери AE: 1.115122, Время: 13.58 сек.\n",
      "Autoencoder сохранён по пути: ./saved_models\\autoencoder_before_finetune.pth\n",
      "encoder.0.weight: requires_grad = True\n",
      "encoder.0.bias: requires_grad = True\n",
      "encoder.1.weight: requires_grad = True\n",
      "encoder.1.bias: requires_grad = True\n",
      "encoder.4.weight: requires_grad = True\n",
      "encoder.4.bias: requires_grad = True\n",
      "encoder.5.weight: requires_grad = True\n",
      "encoder.5.bias: requires_grad = True\n",
      "encoder.8.weight: requires_grad = True\n",
      "encoder.8.bias: requires_grad = True\n",
      "encoder.9.weight: requires_grad = True\n",
      "encoder.9.bias: requires_grad = True\n",
      "encoder.12.weight: requires_grad = True\n",
      "encoder.12.bias: requires_grad = True\n",
      "encoder.13.weight: requires_grad = True\n",
      "encoder.13.bias: requires_grad = True\n",
      "fc_enc.weight: requires_grad = True\n",
      "fc_enc.bias: requires_grad = True\n",
      "fc_dec.weight: requires_grad = True\n",
      "fc_dec.bias: requires_grad = True\n",
      "decoder.0.weight: requires_grad = True\n",
      "decoder.0.bias: requires_grad = True\n",
      "decoder.1.weight: requires_grad = True\n",
      "decoder.1.bias: requires_grad = True\n",
      "decoder.3.weight: requires_grad = True\n",
      "decoder.3.bias: requires_grad = True\n",
      "decoder.4.weight: requires_grad = True\n",
      "decoder.4.bias: requires_grad = True\n",
      "decoder.6.weight: requires_grad = True\n",
      "decoder.6.bias: requires_grad = True\n",
      "decoder.7.weight: requires_grad = True\n",
      "decoder.7.bias: requires_grad = True\n",
      "decoder.9.weight: requires_grad = True\n",
      "decoder.9.bias: requires_grad = True\n",
      "\n",
      "Обучение бинарного классификатора для класса 0...\n",
      "Эпоха 1/10, Class 0, Loss: 0.5136, Accuracy: 85.55%, Время: 9.24 сек.\n",
      "Эпоха 2/10, Class 0, Loss: 0.3496, Accuracy: 88.65%, Время: 9.18 сек.\n",
      "Эпоха 3/10, Class 0, Loss: 0.3130, Accuracy: 89.95%, Время: 9.17 сек.\n",
      "Эпоха 4/10, Class 0, Loss: 0.3143, Accuracy: 89.95%, Время: 9.24 сек.\n",
      "Эпоха 5/10, Class 0, Loss: 0.3028, Accuracy: 90.45%, Время: 9.17 сек.\n",
      "Эпоха 6/10, Class 0, Loss: 0.3034, Accuracy: 89.65%, Время: 9.18 сек.\n",
      "Эпоха 7/10, Class 0, Loss: 0.2925, Accuracy: 89.30%, Время: 9.18 сек.\n",
      "Эпоха 8/10, Class 0, Loss: 0.3120, Accuracy: 89.05%, Время: 9.16 сек.\n",
      "Эпоха 9/10, Class 0, Loss: 0.2978, Accuracy: 90.05%, Время: 9.15 сек.\n",
      "Эпоха 10/10, Class 0, Loss: 0.3054, Accuracy: 89.90%, Время: 9.14 сек.\n",
      "BinaryClassifier для класса 0 сохранён по пути: ./saved_models\\classifier_class_0_before_finetune.pth\n",
      "\n",
      "Обучение бинарного классификатора для класса 1...\n",
      "Эпоха 1/10, Class 1, Loss: 0.5595, Accuracy: 85.20%, Время: 9.30 сек.\n",
      "Эпоха 2/10, Class 1, Loss: 0.3640, Accuracy: 89.55%, Время: 9.79 сек.\n",
      "Эпоха 3/10, Class 1, Loss: 0.3353, Accuracy: 89.70%, Время: 9.41 сек.\n",
      "Эпоха 4/10, Class 1, Loss: 0.3270, Accuracy: 90.20%, Время: 9.27 сек.\n",
      "Эпоха 5/10, Class 1, Loss: 0.3300, Accuracy: 90.05%, Время: 10.51 сек.\n",
      "Эпоха 6/10, Class 1, Loss: 0.3241, Accuracy: 89.90%, Время: 9.99 сек.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Обучение бинарных классификаторов по отдельности\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_classes):\n\u001b[1;32m---> 56\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_binary_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m     trainer\u001b[38;5;241m.\u001b[39msave_classifier(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, suffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbefore_finetune\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Оценка модели до финетюнинга\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[20], line 108\u001b[0m, in \u001b[0;36mTrainer.train_binary_classifier\u001b[1;34m(self, cls, epochs, lr)\u001b[0m\n\u001b[0;32m    106\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    107\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader:\n\u001b[0;32m    109\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), target\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    110\u001b[0m     optimizer_cls\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\git\\MUIV\\concl\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:484\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\git\\MUIV\\concl\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:415\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\git\\MUIV\\concl\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1138\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1131\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1138\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import random\n",
    "\n",
    "# Настройки\n",
    "num_classes = 10\n",
    "latent_dim = 512\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "min_samples_per_class = 200\n",
    "max_test_samples = 2000\n",
    "save_dir = \"./saved_models\"\n",
    "\n",
    "# Подготовка трансформаций с аугментацией данных\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(32),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Загрузка датасетов\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Фильтрация датасетов\n",
    "train_subset = filter_dataset(train_dataset, num_classes, min_samples_per_class)\n",
    "test_subset = filter_dataset(test_dataset, num_classes, min_samples_per_class)\n",
    "\n",
    "# Ограничение тестового набора\n",
    "if len(test_subset) > max_test_samples:\n",
    "    test_indices = random.sample(range(len(test_subset)), max_test_samples)\n",
    "    test_subset = Subset(test_subset, test_indices)\n",
    "\n",
    "# Инициализация тренера\n",
    "trainer = Trainer(num_classes=num_classes, latent_dim=latent_dim, batch_size=batch_size, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", save_dir=save_dir)\n",
    "\n",
    "# Подготовка загрузчиков данных\n",
    "trainer.prepare_dataloaders(train_subset, test_subset)\n",
    "\n",
    "# Обучение автокодировщика\n",
    "trainer.train_autoencoder(epochs=epochs, lr=0.001)\n",
    "\n",
    "# Сохранение автокодировщика\n",
    "trainer.save_autoencoder(suffix=\"before_finetune\")\n",
    "\n",
    "for name, param in trainer.autoencoder.named_parameters():\n",
    "    print(f\"{name}: requires_grad = {param.requires_grad}\")\n",
    "\n",
    "# Обучение бинарных классификаторов по отдельности\n",
    "for cls in range(num_classes):\n",
    "    trainer.train_binary_classifier(cls=cls, epochs=epochs, lr=0.001)\n",
    "    trainer.save_classifier(cls=cls, suffix=\"before_finetune\")\n",
    "\n",
    "# Оценка модели до финетюнинга\n",
    "trainer.acc_combined_before, trainer.error_rate_before, trainer.pred_all_before, trainer.target_all_before = trainer.evaluate_combined_model(\n",
    "    trainer.test_loader, before_finetune=True\n",
    ")\n",
    "\n",
    "# Подсчёт точности по каждому классу до финетюнинга\n",
    "trainer.accuracy_per_class(trainer.pred_all_before, trainer.target_all_before, before_finetune=True)\n",
    "\n",
    "# Визуализация метрик до финетюнинга\n",
    "trainer.plot_metrics(before_finetune=True, after_finetune=False)\n",
    "\n",
    "# Визуализация матрицы ошибок до финетюнинга\n",
    "trainer.plot_confusion_matrix(before_finetune=True, after_finetune=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Часть 1 вариант 2\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import random\n",
    "\n",
    "# Настройки\n",
    "num_classes = 10\n",
    "latent_dim = 512\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "min_samples_per_class = 200  # Увеличено до 200\n",
    "max_test_samples = 10000\n",
    "save_dir = \"./saved_models\"\n",
    "\n",
    "# Подготовка трансформаций с аугментацией данных\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(32),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Загрузка датасетов\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Фильтрация датасетов\n",
    "train_subset = filter_dataset(train_dataset, num_classes, min_samples_per_class)\n",
    "test_subset = filter_dataset(test_dataset, num_classes, min_samples_per_class)\n",
    "\n",
    "# Ограничение тестового набора\n",
    "if len(test_subset) > max_test_samples:\n",
    "    test_indices = random.sample(range(len(test_subset)), max_test_samples)\n",
    "    test_subset = Subset(test_subset, test_indices)\n",
    "\n",
    "# Инициализация тренера\n",
    "trainer = Trainer(num_classes=num_classes, latent_dim=latent_dim, batch_size=batch_size, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", save_dir=save_dir)\n",
    "\n",
    "# Подготовка загрузчиков данных\n",
    "trainer.prepare_dataloaders(train_subset, test_subset)\n",
    "\n",
    "# Обучение автокодировщика\n",
    "trainer.train_autoencoder(epochs=epochs, lr=0.001)\n",
    "\n",
    "# Сохранение автокодировщика\n",
    "trainer.save_autoencoder(suffix=\"before_finetune\")\n",
    "\n",
    "# Оценка модели до финетюнинга\n",
    "trainer.acc_combined_before, trainer.error_rate_before, trainer.pred_all_before, trainer.target_all_before = trainer.evaluate_combined_model(\n",
    "    trainer.test_loader, before_finetune=True\n",
    ")\n",
    "\n",
    "# Подсчёт точности по каждому классу до финетюнинга\n",
    "trainer.accuracy_per_class(trainer.pred_all_before, trainer.target_all_before, before_finetune=True)\n",
    "\n",
    "# Визуализация метрик до финетюнинга\n",
    "trainer.plot_metrics(before_finetune=True, after_finetune=False)\n",
    "\n",
    "# Визуализация матрицы ошибок до финетюнинга\n",
    "trainer.plot_confusion_matrix(before_finetune=True, after_finetune=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Ячейка 2: Загрузка Моделей и Дообучение Энкодера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\inimatic\\AppData\\Local\\Temp\\ipykernel_4500\\3395434850.py:77: FutureWarning:\n",
      "\n",
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder загружен из ./saved_models\\autoencoder_before_finetune.pth\n",
      "Файл ./saved_models\\classifier_class_0_before_finetune.pth не найден.\n",
      "Файл ./saved_models\\classifier_class_1_before_finetune.pth не найден.\n",
      "Файл ./saved_models\\classifier_class_2_before_finetune.pth не найден.\n",
      "Файл ./saved_models\\classifier_class_3_before_finetune.pth не найден.\n",
      "Файл ./saved_models\\classifier_class_4_before_finetune.pth не найден.\n",
      "Файл ./saved_models\\classifier_class_5_before_finetune.pth не найден.\n",
      "Файл ./saved_models\\classifier_class_6_before_finetune.pth не найден.\n",
      "Файл ./saved_models\\classifier_class_7_before_finetune.pth не найден.\n",
      "Файл ./saved_models\\classifier_class_8_before_finetune.pth не найден.\n",
      "Файл ./saved_models\\classifier_class_9_before_finetune.pth не найден.\n",
      "Files already downloaded and verified\n",
      "\n",
      "Дообучение энкодера на небольшой выборке с фиксированными классификаторами...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'epoch_start' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 58\u001b[0m\n\u001b[0;32m     55\u001b[0m trainer\u001b[38;5;241m.\u001b[39mprepare_dataloaders(fine_tune_subset, test_subset)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Дообучение энкодера\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfine_tune_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfine_tune_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfine_tuning_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0005\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Оценка объединённой модели после дообучения\u001b[39;00m\n\u001b[0;32m     61\u001b[0m trainer\u001b[38;5;241m.\u001b[39macc_combined_after, trainer\u001b[38;5;241m.\u001b[39merror_rate_after, trainer\u001b[38;5;241m.\u001b[39mpred_all_after, trainer\u001b[38;5;241m.\u001b[39mtarget_all_after \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate_combined_model(trainer\u001b[38;5;241m.\u001b[39mtest_loader, before_finetune\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[10], line 221\u001b[0m, in \u001b[0;36mTrainer.fine_tune_encoder\u001b[1;34m(self, fine_tune_loader, epochs, lr)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfine_tune_acc_log\u001b[38;5;241m.\u001b[39mappend(epoch_acc)\n\u001b[0;32m    220\u001b[0m ep_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 221\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFine-tuning Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mep\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_acc\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%, Время: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mep_end\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mepoch_start\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m сек.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'epoch_start' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import random\n",
    "\n",
    "# Настройки\n",
    "num_classes = 10\n",
    "latent_dim = 512\n",
    "batch_size = 512  # Увеличено до 512 для стабильности\n",
    "fine_tuning_epochs = 10\n",
    "samples_per_class = 200\n",
    "save_dir = \"./saved_models\"\n",
    "\n",
    "# Подготовка трансформаций без аугментации (можно добавить, если необходимо)\n",
    "transform = transforms.Compose([transforms.Resize(32), transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "\n",
    "# Загрузка датасета для дообучения\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "\n",
    "# Создание выборки для дообучения\n",
    "fine_tune_subset = create_fine_tuning_subset(train_dataset, num_classes, samples_per_class)\n",
    "fine_tune_loader = DataLoader(fine_tune_subset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "# Инициализация тренера\n",
    "trainer = Trainer(num_classes=num_classes, latent_dim=latent_dim, batch_size=batch_size, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", save_dir=save_dir)\n",
    "\n",
    "# Загрузка автокодировщика\n",
    "trainer.load_autoencoder(suffix=\"before_finetune\")\n",
    "\n",
    "# Загрузка бинарных классификаторов\n",
    "for cls in range(num_classes):\n",
    "    trainer.load_classifier(cls=cls, suffix=\"before_finetune\")\n",
    "\n",
    "# Загрузка и фильтрация тестового датасета\n",
    "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "test_subset = filter_dataset(test_dataset, num_classes, min_samples=200)  # Используем тот же min_samples_per_class\n",
    "\n",
    "# Подготовка загрузчиков данных (инициализирует test_loader)\n",
    "trainer.prepare_dataloaders(fine_tune_subset, test_subset)\n",
    "\n",
    "# Дообучение энкодера\n",
    "trainer.fine_tune_encoder(fine_tune_loader, epochs=fine_tuning_epochs, lr=0.0005)\n",
    "\n",
    "# Оценка объединённой модели после дообучения\n",
    "trainer.acc_combined_after, trainer.error_rate_after, trainer.pred_all_after, trainer.target_all_after = trainer.evaluate_combined_model(trainer.test_loader, before_finetune=False)\n",
    "\n",
    "# Подсчёт точности по каждому классу после дообучения\n",
    "trainer.accuracy_per_class(trainer.pred_all_after, trainer.target_all_after, before_finetune=False)\n",
    "\n",
    "# Сохранение автокодировщика после дообучения\n",
    "trainer.save_autoencoder(suffix=\"after_finetune\")\n",
    "\n",
    "# Сохранение бинарных классификаторов после дообучения\n",
    "for cls in range(num_classes):\n",
    "    trainer.save_classifier(cls=cls, suffix=\"after_finetune\")\n",
    "\n",
    "# Визуализация метрик после дообучения\n",
    "trainer.plot_metrics(before_finetune=False, after_finetune=True)\n",
    "\n",
    "# Визуализация матрицы ошибок после дообучения\n",
    "trainer.plot_confusion_matrix(before_finetune=False, after_finetune=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
